---
title: "Human scheduling of perceptual tasks"
site: workflowr::wflow_site
output:
  workflowr::wflow_html:
    toc: true
editor_options:
  chunk_output_type: console
---

Daniel R. Little^1^, Ami Eidels^2^, and Deborah J. Lin^1^


^1^ The University of Melbourne, ^2^ The University of Newcastle

# Scheduling Project

Details regarding our study are provided here: [Preregistration Document](prereg.html)

```{r data_load, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
rm(list=ls())
library(tidyverse)
library(workflowr)
#library(Rankcluster)
#library(rankdist) # Crashes rStudio
#library(Kendall)
library(DescTools) # ConDisPairs looks useful
library(gtools) 
library(english)
library(ggplot2)
library(dplyr)
library(hrbrthemes)
library(knitr)
library(reshape2)

#define working directories
inputdir <- "data"

# Reading data and variable names 
fixed_datafilename = "200511_fixed_rdk_data.csv"
random_datafilename = "200525_random_rdk_data.csv"

colfile       <- read.csv(paste(inputdir,"data_dictionary.csv",sep="/"))
fixed_datafn  <- paste(inputdir,fixed_datafilename,sep="/") 
random_datafn <- paste(inputdir,random_datafilename,sep="/") 
fixd_rawdata     <- read.csv(fixed_datafn, header = FALSE, col.names = colfile$Column) # Add column labels to data
rand_rawdata     <- read.csv(random_datafn, header = FALSE, col.names = colfile$Column) # Add column labels to data

# Summary data
fixedLoggedSubjects  = unique(fixd_rawdata$uniqueid)  # Unique subject numbers
nFixedLoggedSubjects = length(fixedLoggedSubjects) # Number of subjects who logged into the website using the link

randomLoggedSubjects  = unique(rand_rawdata$uniqueid)   # Unique subject numbers
nRandomLoggedSubjects = length(randomLoggedSubjects) # Number of subjects who logged into the website using the link

```

# Data Preprocessing

_Data Cleaning_

Two experiments were completed online: one using fixed task locations on each trial and one using random task locations on each trial. Subjects completed the experiment by clicking a link with the uniquely generated id code. Subjects were able to use the link multiple times; further, subjects were able to exit the experiment at any time. Consequently, the datafile contains partially completed data for some subjects which needs to be identified and removed. 

```{r data_cleaning, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# A full data set has 10 practice trials (0 to 9) and 30 deadline trials (0 to 29)
# A full data set will have a max trial number of 29 
nTotalTrials = 29 # Counting from trial 0
cleanUpData = function(rawdata, nTotalTrials){
  
  completeSubjects = unique(rawdata$subject[rawdata$trial_number == nTotalTrials]) # Unique subject ids
  nCompleteSubjects = length(completeSubjects) # Nubmer of complete data files

  cleandata = rawdata[rawdata$subject %in% completeSubjects, ] # keep only complete data files
  # some subjects may have completed the experiment twice, keep only first completion
  subids = distinct(as.data.frame(cbind(cleandata$subject, cleandata$uniqueid)))
  names(subids) = c("subject", "uniqueid")
  
  # repeated uniqueids indicate duplicate completion
  nRepeats = sum(duplicated(subids$uniqueid))
  nonrepeatedsubs = subids$subject[which(!duplicated(subids$uniqueid))]
  
  # keep only nonrepeated subs
  data = cleandata[cleandata$subject %in% nonrepeatedsubs, ]
  
  # Summary data
  subjects = unique(data$uniqueid)           # Unique subject numbers
  nSubjects = length(unique(data$uniqueid))  # Number of subjects
  
  return(list("data"=data, "subjects"=subjects, "nSubjects"=nSubjects, "nRepeats"=nRepeats))
}

fd = cleanUpData(fixd_rawdata, nTotalTrials)
rd = cleanUpData(rand_rawdata, nTotalTrials)

```

```{r add_phase, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}


# Add in phase column which indicates whether current trials are practice or experiment
add_phase_col = function(data){
  data$data$phase = rep(NA, nrow(data$data))
  for (i in 1:data$nSubjects){
    
    # Find point at which trial_index = 0 later in the trial
    tidx = which(data$data$trial_number[data$data$uniqueid == data$subjects[i]] == 0)
    idx = tidx[which(diff(tidx) > 1) + 1]
    
    dsize = nrow(data$data[data$data$uniqueid == data$subjects[i], ])
    data$data$phase[data$data$uniqueid == data$subjects[i]] = c(NA, rep(0, idx-2), rep(1,length(idx:(dsize-1))), NA)
  }

  return(data)
}

fd = add_phase_col(fd)
rd = add_phase_col(rd)

```


```{r emails, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Need to extract emails for sending results from all datasets
# trial_event = email

data = rbind(fd$data, rd$data)

demographics = data$responses[data$trial_event == "demographics"]
emails = as.character(demographics[grep("Email", demographics)])
colon_loc = gregexpr(pattern = ":", emails)

nSubjects = fd$nSubjects+rd$nSubjects
full_email_list = rep(NA, nSubjects)
for (i in 1:nSubjects){
  if (!is.na(emails[i])){
    full_email_list[i] = substr(emails[i], colon_loc[[i]][1]+2, nchar(emails[i])-2)
  }
}
email_list = str_sort(full_email_list[full_email_list != "" & !is.na(full_email_list)])

```

```{r demographics, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Demographics
# trial_event = sex_age
# responses --> Gender and Age
processDemographics = function(data, nSubjects){

  demographics = data$responses[data$trial_event == "demographics"]
  sexage = as.character(demographics[grep("Gender", demographics)])
  
  colon_loc = gregexpr(pattern = ":", sexage)
  comma_loc = gregexpr(pattern = ",", sexage)
  
  sex = rep(NA, nSubjects)
  age = rep(NA, nSubjects)
  for (i in 1:nSubjects){
    sex[i] = toupper(substr(sexage[i], colon_loc[[i]][1]+2, comma_loc[[i]][1]-2))
    
    x = substr(sexage[i], colon_loc[[i]][2]+2, nchar(sexage[i])-2)
    if (nchar(x) == 2){
      age[i] = as.numeric(x)
    } else {
      age[i] = as.numeric(substr(sexage[i], colon_loc[[i]][2]+2, colon_loc[[i]][2]+4))    
    }
  }
  
  nFemales = sum(sex == "FEMALE" | sex == "WOMEN")
  nMales = sum(sex == "MALE")
  nOther = sum(sex != "FEMALE" & sex != "MALE" & sex != "WOMEN")
  
  meanAge = mean(age, na.rm = TRUE)
  stdAge  = sd(age, na.rm = TRUE)
  
  return(list(nFemales, nMales, nOther, meanAge, stdAge, age))
}

fixedDemo = processDemographics(fd$data, fd$nSubjects)
names(fixedDemo) = c("nFemales", "nMales", "nOthers", "meanAge", "stdAge", "ages")
randDemo = processDemographics(rd$data, rd$nSubjects)
names(randDemo) = c("nFemales", "nMales", "nOthers", "meanAge", "stdAge", "ages")

```
# Method

## Participants

We tested `r fd$nSubjects + rd$nSubjects` participants (`r fixedDemo$nFemales+randDemo$nFemales` F, `r fixedDemo$nMales+randDemo$nMales` M, `r fixedDemo$nOthers+randDemo$nOthers` Undeclared). Participants were recruited through the Melbourne School of Psychological Sciences Research Experience Pool (Mean age = `r round(mean(c(fixedDemo$ages, randDemo$ages), na.rm=TRUE),2) `, range = `r min(c(fixedDemo$ages, randDemo$ages), na.rm=TRUE) ` - `r max(c(fixedDemo$ages, randDemo$ages), na.rm=TRUE)`). Participants were reimbursed with credit toward completion of a first year psychology subject. Datasets from `r fd$nRepeats + rd$nRepeats` subjects were excluded for completing the experiment twice; i.e., only the first of the datasets for these subjects was retained.

`r paste(toupper(substring(english(fd$nSubjects), 1, 1)), substring(english(fd$nSubjects), 2), sep="")` were assigned to the _Fixed Difficulty_ condition. In this condition, the location of easy, medium, hard, and very hard random dot kinematograms (RDK's) was held constant across trials. 

`r paste(toupper(substring(english(rd$nSubjects), 1, 1)), substring(english(rd$nSubjects), 2), sep="")` were assigned to the _Random Difficulty_ condition. In this condition, the location of easy, medium, hard, and very hard random dot kinematograms (RDK's) were randomized from trial to trial. 

The Fixed Difficulty experiment was completed before the Random Difficulty experiment. Participants only completed one of these.


## Design

```{r getCoherence, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
coherence_set = sort(unique(as.numeric(c(data$patch_0, data$patch_1, data$patch_2, data$patch_3))), decreasing=TRUE)
```

In each condition, participants completed multiple trials in which they selected and completed RDK tasks. On each trial, participants were shown a set of four RDKs labelled Easy, Medium, Hard, and Very Hard. The labels corresponded to the difficulty of the RDK. The proportion of dots moving in a coherent direction was set to 0.8, 0.5, 0.2, and 0.0 for the Easy, Medium, Hard, and Very Hard locations, respectively.

From the set of four, participants selected and completed one RDK at a time in any order. The goal of each trial was to complete as many as possible before a deadline. 

Participants first completed 10 trials with a long (60 sec) deadline to help participants learn the task, explore strategies, and allow for comparison to a short-deadline condition. We term this the _no deadline_ condition since the provided time is well beyond what is necessary to complete all four RDK's. Next, participants completed 30 trials with a 6 second deadline.


# Data Analysis

```{r analyse_RDK_difficulty, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
rdk = data[data$trial_event == "rdk", ]
rdk$correct = as.numeric(rdk$correct)
rdk$correct = rdk$correct - 1
#rdk$correct[is.na(rdk$correct)] = 0
#rdk$correct[rdk$correct == 2] = 1

# Remove timeouts
rdk = rdk[rdk$rt != -1, ]
rdk$rt = as.numeric(as.character(rdk$rt))

nlongrts = sum(rdk$rt > 3000)
rdk = rdk[rdk$rt <3000, ]

rdk$phase = as.factor(rdk$phase)

# Fix missing 0's in data$correct[data$trial_event == "rdk"] column
difficulty = aggregate(list("accuracy" = rdk$correct, "rt" = rdk$rt), by = list("difficulty" =        rdk$dot_coherence, "phase" = rdk$phase, "condition" = rdk$condition), FUN = function(x) mean(x, na.rm = TRUE))
ncounts = rdk %>% count(phase, dot_coherence)
difficulty$n = ncounts$n
difficulty$accuracy = round(difficulty$accuracy, 2)
difficulty$rt = round(difficulty$rt, 2)

levels(difficulty$difficulty) = c("Very Hard", "Hard", "Medium", "Easy", "NULL")
levels(difficulty$phase) = c("no deadline", "deadline")

# Create the table
kable(difficulty, caption="Mean accuracy and RT for each difficulty and each phase")

```

```{r task_completion, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
tcdata = aggregate(rdk$trial_event[rdk$correct == 1], by=list("trial" = rdk$trial_number[rdk$correct == 1], "phase" = rdk$phase[rdk$correct == 1], "subject" = rdk$uniqueid[rdk$correct == 1]), FUN=length)

avgCompletions = aggregate(tcdata$x, by=list("phase"=tcdata$phase), FUN=mean)
levels(avgCompletions$phase) = c("no deadline", "deadline")

```

We first summarize performance by answering the following: 

* How many tasks are completed on average?

On average, across both conditions, participants completed `r round(avgCompletions$x[avgCompletions$phase == "no deadline"],2)` tasks during the `r as.character(avgCompletions$phase[1])` phase and `r round(avgCompletions$x[avgCompletions$phase == "deadline"],2)` tasks during the `r as.character(avgCompletions$phase[2])` phase. 

* TODO: What is the average time taken to complete the RDK's?

* TODO: Did this differ between the fixed and random location conditions?

* What is the average completion time and accuracy of the easy, medium, hard, and very hard tasks? The results indicated that the RTs became faster as the difficulty if the RDK became easier. 

```{r difficulty_plot, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# Difficulty plot
levels(rdk$dot_coherence) = c("very hard", "hard", "medium", "easy", "NULL")
levels(rdk$phase) = c("no deadline", "deadline")
diff_plot <- rdk %>% ggplot(aes(x=dot_coherence, y=rt, fill=dot_coherence)) + geom_violin(adjust = 1.5, trim = TRUE) + facet_wrap(~phase) + labs(y="RT (msec)", x = "Difficulty")

print(diff_plot + ggtitle("Response times as a function of difficulty"))
```


```{r distcomp, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
n = 4 # Number of tasks

# Distance parameters
maxdistance = (n * (n-1))/2
missing_penalty = maxdistance/n
allperms = permutations(n=4, r=4, v=1:4, repeats.allowed=FALSE)
nperms = nrow(allperms)

# Processing functions
splitData = function(data){
  pracdata = data[data$trial_event == "practice_rdk", ]
  exp_data = data[data$trial_event == "select_rdk", ]
  return(list("practice" = pracdata, "experiment" = exp_data))
}

# Compute distance from optimal for all perms
opt_order_set = function(trial_optimal_order, nperms=nperms, allperms=allperms){
  pdist <- rep(NA, nperms)
  for (i in 1:nperms){
    distObj = ConDisPairs(table(allperms[i, ], trial_optimal_order$ix))
    pdist[i] = distObj$D  
  }
  return(pdist)
}
# Usage: opt_order_set(poptimal_order[[1]], nperms, allperms)

# Compute distance from optimal for each trial during practice
get_trial_scores = function(sdata, ntrials, n, nperms, allperms, nSubjects, subjects){

  # preallocate variables for output
  max_distances <- matrix(data=NA, nrow=nSubjects, ncol=ntrials)
  min_distances <- matrix(data=NA, nrow=nSubjects, ncol=ntrials)
  avg_distances <- matrix(data=NA, nrow=nSubjects, ncol=ntrials)
  count_matrix = matrix(0,length(coherence_set),length(coherence_set))
  
  for (j in 1:nSubjects){
        # select out data for subject j
        tdata = sdata[sdata$uniqueid == subjects[j], ]
        
        # preallocated subject specific task selection matrix
        selmat <- matrix(data=NA, nrow=ntrials, ncol=n)
        optorder <- matrix(data=NA, nrow=ntrials, ncol=n)
        difforder <- matrix(data=NA, nrow=ntrials, ncol=n)
    for (i in 1:ntrials){
        
        # Get the task selection order for the current trial (may be incomplete if timed out)
        csel = tdata[tdata$trial_number == i-1, ]$button_pressed
        selmat[i, 1:length(csel)] = csel # NULL is coded as option 5
        selmat[i, selmat[i,] == 5] = NA  # Replace NULL with NA
        
        # Get the locations of easy, med, hard, etc
        patch_order = c(as.numeric(as.character(unique(tdata[tdata$trial_number == i-1, ]$patch_0))), as.numeric(as.character(unique(tdata[tdata$trial_number == i-1, ]$patch_1))), as.numeric(as.character(unique(tdata[tdata$trial_number == i-1, ]$patch_2))), as.numeric(as.character(unique(tdata[tdata$trial_number == i-1, ]$patch_3))))
        
        # Find the order in which easy, med, hard, etc were selected
        difforder[i,] = patch_order[selmat[i,]]
        
        for (k in 1:n){
          count_matrix[which(difforder[i,] == coherence_set[k]), k] = count_matrix[which(difforder[i,] == coherence_set[k]), k] + 1
        }
        
        # Get the optimal order
        order_to_compare = sort(patch_order, decreasing=TRUE, index.return = TRUE)
        optorder[i, ] = order_to_compare$ix
        
        # compute distances of all permutations to indicated order
        pdist = opt_order_set(order_to_compare, nperms, allperms)
        
        # Find permutation partial matches
        if (!all(is.na(selmat[i,]))){
          partial_perms = allperms[apply(do.call("rbind", rep(list(selmat[i,1:sum(!is.na(selmat[i,]))]), nperms)) == allperms[, !is.na(selmat[i,])], 1, function(x)all(x)), ]
        
          # Find distances consistent with partial matches
          partial_distances = pdist[apply(do.call("rbind", rep(list(selmat[i,1:sum(!is.na(selmat[i,]))]), nperms)) == allperms[, !is.na(selmat[i,])], 1, function(x)all(x))]
        } else {
          partial_distances = pdist
        }
        
        # Outputs
        max_distances[j,i] = max(partial_distances)  # Maximum distance of partial matches
        min_distances[j,i] = min(partial_distances)  # Maximum distance of partial matches
        avg_distances[j,i] = mean(partial_distances) # Average distance of partial matches
        
        
    }
    
    # Create better organised matrix of selections    
    if (j == 1){
      fullmat = cbind(rep(subjects[j], ntrials), selmat)
      fullopt = cbind(rep(subjects[j], ntrials), optorder)
      fulldiff = cbind(rep(subjects[j], ntrials), difforder)
    } else {
      fullmat = rbind(fullmat, cbind(rep(subjects[j], ntrials), selmat))
      fullopt = rbind(fullopt, cbind(rep(subjects[j], ntrials), optorder))
      fulldiff = rbind(fulldiff, cbind(rep(subjects[j], ntrials), difforder))
    }    
  }

  # Compute matches by subject for first selection, first two selections, first three selections
  match1 = aggregate(cbind(fullmat[,1], fullmat[,2]==fullopt[,2]), by=list(fullmat[,1]), FUN = mean)
  match2 = aggregate(cbind(fullmat[, 1], apply(fullmat[,2:3] == fullopt[,2:3], 1, all)), by=list(fullmat[,1]), FUN = mean)
  match3 = aggregate(cbind(fullmat[, 1], apply(fullmat[,2:4] == fullopt[,2:4], 1, all)), by=list(fullmat[,1]), FUN = mean)
  # match4 = aggregate(cbind(fullmat[, 1], apply(fullmat[,2:5] == fullopt[,2:5], 1, all)), by=list(fullmat[,1]), FUN = mean) # same as match3
  matches = as.data.frame(cbind(match1$V1, match1$V2, match2$V2, match3$V2))
  names(matches) = c("subjects", "match1", "match2", "match3")
  
  return(list("selections" = fullmat, "optimal_orders" = fullopt, "diff_orders" = fulldiff, "selection_counts" = count_matrix, "matches" = matches, "max_distances" = max_distances, "min_distances" = min_distances, "avg_distances" = avg_distances))
}

# Compute distances for condition x practice/experiment
# sdata, order_to_compare, ntrials, n, nperms, allperms, nSubjects, subjects
# sdata = splitData(fd$data)$practice
# order_to_compare = fp$optimal_order
# ntrials = fp$ntrials
# nSubjects =fd$nSubjects
# subjects = fd$subjects
scores = list("fixed" = list("practice" = get_trial_scores(splitData(fd$data)$practice, 10, 
                                                           n, nperms, allperms, fd$nSubjects, fd$subjects), 
                             "experiment" = get_trial_scores(splitData(fd$data)$experiment, 30, 
                                                           n, nperms, allperms, fd$nSubjects, fd$subjects)), 
              "random" = list("practice" = get_trial_scores(splitData(rd$data)$practice, 10, 
                                                           n, nperms, allperms, rd$nSubjects, rd$subjects), 
                              "experiment" = get_trial_scores(splitData(rd$data)$experiment, 30, 
                                                           n, nperms, allperms, rd$nSubjects, rd$subjects)))


```


```{r buildComparison, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
fcon = data.frame(condition = as.factor(rep(1, fd$nSubjects*10)), 
                  subjects = rep(1:fd$nSubjects + 100, each=10), 
                  trials = rep(1:10, fd$nSubjects), 
                  max_practice = matrix(t(scores$fixed$practice$max_distances), 10*nrow(scores$fixed$practice$max_distances), byrow= FALSE), 
                  max_expFirst10 = matrix(t(scores$fixed$experiment$max_distances[, 1:10]), 10*nrow(scores$fixed$experiment$max_distances), byrow= FALSE), 
                  max_expLast10 = matrix(t(scores$fixed$experiment$max_distances[, 21:30]), 10*nrow(scores$fixed$experiment$max_distances), byrow= FALSE), 
                  min_practice = matrix(t(scores$fixed$practice$min_distances), 10*nrow(scores$fixed$practice$min_distances), byrow= FALSE), 
                  min_expFirst10 = matrix(t(scores$fixed$experiment$min_distances[, 1:10]), 10*nrow(scores$fixed$experiment$min_distances), byrow= FALSE), 
                  min_expLast10 = matrix(t(scores$fixed$experiment$min_distances[, 21:30]), 10*nrow(scores$fixed$experiment$min_distances), byrow= FALSE),                   
                  avg_practice = matrix(t(scores$fixed$practice$avg_distances), 10*nrow(scores$fixed$practice$avg_distances), byrow= FALSE), 
                  avg_expFirst10 = matrix(t(scores$fixed$experiment$avg_distances[, 1:10]), 10*nrow(scores$fixed$experiment$max_distances), byrow= FALSE), 
                  avg_expLast10  = matrix(t(scores$fixed$experiment$avg_distances[, 21:30]), 10*nrow(scores$fixed$experiment$max_distances), byrow= FALSE))

rcon = data.frame(condition = as.factor(rep(2, rd$nSubjects*10)), 
                  subjects = rep(1:rd$nSubjects + 200, each=10), 
                  trials = rep(1:10, rd$nSubjects), 
                  max_practice = matrix(t(scores$random$practice$max_distances), 10*nrow(scores$random$practice$max_distances), byrow= FALSE), 
                  max_expFirst10 = matrix(t(scores$random$experiment$max_distances[, 1:10]), 10*nrow(scores$random$experiment$max_distances), byrow= FALSE), 
                  max_expLast10 = matrix(t(scores$random$experiment$max_distances[, 21:30]), 10*nrow(scores$random$experiment$max_distances), byrow= FALSE), 
                  min_practice = matrix(t(scores$random$practice$min_distances), 10*nrow(scores$random$practice$min_distances), byrow= FALSE), 
                  min_expFirst10 = matrix(t(scores$random$experiment$min_distances[, 1:10]), 10*nrow(scores$random$experiment$min_distances), byrow= FALSE), 
                  min_expLast10 = matrix(t(scores$random$experiment$min_distances[, 21:30]), 10*nrow(scores$random$experiment$min_distances), byrow= FALSE),                   
                  avg_practice = matrix(t(scores$random$practice$avg_distances), 10*nrow(scores$random$practice$avg_distances), byrow= FALSE), 
                  avg_expFirst10 = matrix(t(scores$random$experiment$avg_distances[, 1:10]), 10*nrow(scores$random$experiment$max_distances), byrow= FALSE), 
                  avg_expLast10  = matrix(t(scores$random$experiment$avg_distances[, 21:30]), 10*nrow(scores$random$experiment$max_distances), byrow= FALSE))

expdata = rbind(fcon, rcon)

# Set up summary data dataframe: maximum partial completion efficiency
max_a = setNames(aggregate(expdata$max_practice, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))
max_b = setNames(aggregate(expdata$max_expFirst10, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))
max_c = setNames(aggregate(expdata$max_expLast10, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))

avg_maxdata = rbind(cbind(max_a, phase=rep("untimed practice", nrow(max_a))), 
                    cbind(max_b, phase=rep("deadline early", nrow(max_b))), 
                    cbind(max_c, phase=rep("deadline late", nrow(max_c))))
avg_maxdata$phase = as.factor(avg_maxdata$phase)         # Convert phase to factor
levels(avg_maxdata$condition) = c("fixed", "random") # Replace condition names

# Set up summary data dataframe: minimum partial completion efficiency
min_a = setNames(aggregate(expdata$min_practice, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))
min_b = setNames(aggregate(expdata$min_expFirst10, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))
min_c = setNames(aggregate(expdata$min_expLast10, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))

avg_mindata = rbind(cbind(min_a, phase=rep("untimed practice", nrow(min_a))), 
                    cbind(min_b, phase=rep("deadline early", nrow(min_b))), 
                    cbind(min_c, phase=rep("deadline late", nrow(min_c))))
avg_mindata$phase = as.factor(avg_mindata$phase)         # Convert phase to factor
levels(avg_mindata$condition) = c("fixed", "random") # Replace condition names

# Set up summary data dataframe: avg partial completion efficiency
avg_a = setNames(aggregate(expdata$avg_practice, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))
avg_b = setNames(aggregate(expdata$avg_expFirst10, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))
avg_c = setNames(aggregate(expdata$avg_expLast10, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))

avg_avgdata = rbind(cbind(avg_a, phase=rep("untimed practice", nrow(avg_a))), 
                    cbind(avg_b, phase=rep("deadline early", nrow(avg_b))), 
                    cbind(avg_c, phase=rep("deadline late", nrow(avg_c))))
avg_avgdata$phase = as.factor(avg_avgdata$phase)         # Convert phase to factor
levels(avg_avgdata$condition) = c("fixed", "random") # Replace condition names


# Set up summary data for matches
set1 = cbind(rep("fixed",fd$nSubjects), rep("untimed" ,fd$nSubjects), scores$fixed$practice$matches)
names(set1) = c("condition", "phase", "subjects", "match1", "match2", "match3")
set2 = cbind(rep("fixed",fd$nSubjects), rep("deadline" ,fd$nSubjects), scores$fixed$experiment$matches)
names(set2) = c("condition", "phase", "subjects", "match1", "match2", "match3")
set3 = cbind(rep("random",rd$nSubjects), rep("untimed" ,rd$nSubjects), scores$random$practice$matches)
names(set3) = c("condition", "phase", "subjects", "match1", "match2", "match3")
set4 = cbind(rep("random",rd$nSubjects), rep("deadline" ,rd$nSubjects), scores$random$experiment$matches)
names(set4) = c("condition", "phase", "subjects", "match1", "match2", "match3")

match_mat = rbind(set1, set2, set3, set4)

```


# Optimality in each condition

The task set presented to each subject will have an optimal solution (ordered from easiest to most difficult). We first ask: 

* What is the proprotion of easy, medium, hard, and very hard patches selected first, second, third or fourth?

```{r selectionOrderAnalysis, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}

# selection_counts [rows are choice order (1,2,3,4), columns are diffculty (easy,med, hard,vhard)]

# Convert to proportions
fpmat = t(apply(scores$fixed$practice$selection_counts, 1, function(x) x/sum(x)))
femat = t(apply(scores$fixed$experiment$selection_counts, 1, function(x) x/sum(x)))
rpmat = t(apply(scores$random$practice$selection_counts, 1, function(x) x/sum(x)))
remat = t(apply(scores$random$experiment$selection_counts, 1, function(x) x/sum(x)))

fpmelt = melt(fpmat)
femelt = melt(femat)
rpmelt = melt(rpmat)
remelt = melt(remat)
names(fpmelt) = c("Difficulty", "Order", "value")
names(femelt) = c("Difficulty", "Order", "value")
names(rpmelt) = c("Difficulty", "Order", "value")
names(remelt) = c("Difficulty", "Order", "value")

hm = rbind(cbind("condition" = rep("Fixed No Deadline", nrow(fpmelt)), fpmelt), 
           cbind("condition" = rep("Fixed Deadline", nrow(fpmelt)), femelt),
           cbind("condition" = rep("Random No Deadline", nrow(fpmelt)), rpmelt),
           cbind("condition" = rep("Random Deadline", nrow(fpmelt)), remelt))

hmplot = ggplot(hm, aes(x=Difficulty, y=Order)) +
          geom_tile(aes(fill=value)) +
          scale_fill_gradientn(colours=c("blue","pink", "red")) +
          geom_text(aes(label=round(value, 2))) + 
          scale_y_reverse() +
          facet_wrap(~condition) + 
          labs(y="Choice", x = "Difficulty")
print(hmplot)

```

* We next ask whether the sequence of choices reflected the optimal order: What is the proportion of easy-task-first choices in each condition? Of easy-then-medium? Of easy-medium-then-hard?

```{r analyseMatches, fig.height = 10, fig.width = 9, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
avgMatch = aggregate(list("easy first"=match_mat$match1, "easy-med"=match_mat$match2, "easy-med-hard"=match_mat$match3), by = list("phase"=match_mat$phase, "condition"=match_mat$condition), FUN = function(x)mean(x,na.rm=TRUE))

avgMatch$easy.first = round(avgMatch$easy.first,2)
avgMatch$easy.med = round(avgMatch$easy.med,2)
avgMatch$easy.med.hard = round(avgMatch$easy.med.hard,2)

# Create the table
kable(avgMatch, caption="Average optimal choices")

long_match = melt(match_mat, id.var = c("condition", "phase"), measure.var = c("match1", "match2", "match3"), variable.name = "match")
levels(long_match$match) = c("Order = Easy", "Order = Easy, Medium", "Order = Easy, Medium, Hard")

match_plot <- long_match %>% ggplot(aes(x=value, fill=match)) + geom_histogram(color="white", alpha=0.6, bins = 10, position="identity") + facet_wrap(~condition+phase+match, nrow=4, ncol = 3) + labs(y="Participant Frequency", x = "Proportion of First Choices")

print(match_plot + ggtitle("Optimally Ordered Responses")) 

```



The next analysis will compute something like Kendall's Tau, rank-order distance, which ranges between 0 (perfect match) and 6 (maximally distant), for 4 options. 

What we want is the distance of the selected options from the optimal solutions, which is Kendall's Tau. However, because a participant may run out of time, there may be missing values. To handle these values, for each trial, we find the orders which partially match the selected order and compute three measures of performance: 
1. the maximum distance of those possible orders and the optimal solution (*max_distance*). This analysis is biased against optimality because it assumes that partially completed sequences would have eventually been non-optimal. 

2. the minimum distance of the partial orders and the optimal solution (*min_distance*). This analysis is biased toward optimality because it assumes that partially completed sequences would have eventually been closer to optimal.  

3. the average distance of those possible orders and the optimal solution (*avg_distance*). 


The following figures compare max_distance, min_distance, and avg_distance between the fixed difficulty and random difficulty conditions as a function of deadline condition and phase. 

```{r plotData, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
max_plot <- avg_maxdata %>% ggplot(aes(x=avg, fill=phase)) + geom_histogram(color="white", alpha=0.6, bins = 10, position="identity") + facet_wrap(~condition+phase) + labs(y="Frequency", x = "Max Distance")

min_plot <- avg_mindata %>% ggplot(aes(x=avg, fill=phase)) + geom_histogram(color="white", alpha=0.6, bins = 10, position="identity") + facet_wrap(~condition+phase) + labs(y="Frequency", x = "Min Distance")

avg_plot <- avg_avgdata %>% ggplot(aes(x=avg, fill=phase)) + geom_histogram(color="white", alpha=0.6, bins = 10, position="identity") + facet_wrap(~condition+phase) + labs(y="Frequency", x = "Avg Distance")

print(max_plot + ggtitle("Max Distance"))
print(min_plot + ggtitle("Min Distance"))
print(avg_plot + ggtitle("Avg Distance"))

```

# Alternative response strategies

An alternative possible strategy involves selecting tasks based on spatial position. One salient strategy would be to start with a task and then select the remaining tasks in clockwise and anti-clockwise order. 

```{r spatial_analysis, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}

clockwise = rbind(c(0, 1, 2, 3), c(1, 2, 3, 0), c(2, 3, 0, 1), c(3, 0, 1, 2))
anticlockwise = rbind(c(0, 3, 2, 1), c(1, 0, 3, 2), c(2, 1, 0, 3), c(3, 2, 1, 0))
spatial_orders = rbind(clockwise, anticlockwise)

# Code whether each selection is consistent or inconsistent with a circular strategy
get_spatial_consistency = function(sdata, spatial_orders, ntrials, n, nSubjects, subjects){
  
  # preallocate variables for output
  spatial_choice_scores <- matrix(data=NA, nrow=nSubjects, ncol=ntrials)
  spatial_display_scores <- matrix(data=NA, nrow=nSubjects, ncol=ntrials)
  for (j in 1:nSubjects){
    # select out data for subject j
    tdata = sdata[sdata$uniqueid == subjects[j], ]
    
    # preallocated subject specific task selection matrix
    #selmat <- matrix(data=NA, nrow=ntrials, ncol=n)
    for (i in 1:ntrials){

        # Get the task selection order for the current trial (may be incomplete if timed out)
        csel = tdata[tdata$trial_number == i-1, ]$button_pressed
        csel[csel==5] = NA # NULL is coded as option 5, Replace NULL with NA
        csel = as.numeric(as.character(as.matrix(csel)))
        
        #selmat[i, 1:length(csel)] = csel # NULL is coded as option 5
        #selmat[i, selmat[i,] == 5] = NA  # Replace NULL with NA
        
        # Get coherence order for the current trial
        coh = c(tdata[tdata$trial_number == i-1, ]$patch_0[1], tdata[tdata$trial_number == i-1, ]$patch_1[1], tdata[tdata$trial_number == i-1, ]$patch_2[1], tdata[tdata$trial_number == i-1, ]$patch_3[1])
        
        cohOrder = order(coh) # Locations of each difficulty (very hard, hard, med, easy)
        
        # Code trial and coherence as spatially consistent or not
        spatial_choice_scores[j,i] = as.numeric(any(apply(spatial_orders[ , 1:3], 1, function(x) identical(x, csel[1:3]))))
        spatial_display_scores[j,i] = as.numeric(any(apply(spatial_orders[ , 1:3], 1, function(x) identical(x, cohOrder[1:3]-1))))
    }
  }
  return(list("choice" = spatial_choice_scores, "display" = spatial_display_scores))
}


# Compute responses consistent with a spatial strategy
# sdata, spatial_orders, ntrials, n, nSubjects, subjects
spatial_scores = list("fixed" = list("practice" = get_spatial_consistency(splitData(fd$data)$practice, spatial_orders, 10, 
                                                         n, fd$nSubjects, fd$subjects), 
                            "experiment" = get_spatial_consistency(splitData(fd$data)$experiment, spatial_orders, 30,
                                                         n, fd$nSubjects, fd$subjects)), 
             "random" = list("practice" = get_spatial_consistency(splitData(rd$data)$practice, spatial_orders, 10, 
                                                         n, rd$nSubjects, rd$subjects), 
                            "experiment" = get_spatial_consistency(splitData(rd$data)$experiment, spatial_orders, 30,
                                                         n, rd$nSubjects, rd$subjects)))

```


```{r buildSpatialComparison, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
fscon = data.frame(condition = as.factor(rep(1, fd$nSubjects*10)), 
                  subjects = rep(1:fd$nSubjects + 100, each=10), 
                  trials = rep(1:10, fd$nSubjects), 
                  sc_practice = matrix(t(spatial_scores$fixed$practice$choice), 10*nrow(spatial_scores$fixed$practice$choice), byrow= FALSE), 
                  sc_expFirst10 = matrix(t(spatial_scores$fixed$experiment$choice[, 1:10]), 10*nrow(spatial_scores$fixed$experiment$choice), byrow= FALSE), 
                  sc_expLast10 = matrix(t(spatial_scores$fixed$experiment$choice[, 21:30]), 10*nrow(spatial_scores$fixed$experiment$choice), byrow= FALSE), 
                  sd_practice = matrix(t(spatial_scores$fixed$practice$display), 10*nrow(spatial_scores$fixed$practice$display), byrow= FALSE), 
                  sd_expFirst10 = matrix(t(spatial_scores$fixed$experiment$display[, 1:10]), 10*nrow(spatial_scores$fixed$experiment$display), byrow= FALSE), 
                  sd_expLast10  = matrix(t(spatial_scores$fixed$experiment$display[, 21:30]), 10*nrow(spatial_scores$fixed$experiment$display), byrow= FALSE))

rscon = data.frame(condition = as.factor(rep(2, rd$nSubjects*10)), 
                  subjects = rep(1:rd$nSubjects + 200, each=10), 
                  trials = rep(1:10, rd$nSubjects), 
                  sc_practice = matrix(t(spatial_scores$random$practice$choice), 10*nrow(spatial_scores$random$practice$choice), byrow= FALSE), 
                  sc_expFirst10 = matrix(t(spatial_scores$random$experiment$choice[, 1:10]), 10*nrow(spatial_scores$random$experiment$choice), byrow= FALSE), 
                  sc_expLast10 = matrix(t(spatial_scores$random$experiment$choice[, 21:30]), 10*nrow(spatial_scores$random$experiment$choice), byrow= FALSE), 
                  sd_practice = matrix(t(spatial_scores$random$practice$display), 10*nrow(spatial_scores$random$practice$display), byrow= FALSE), 
                  sd_expFirst10 = matrix(t(spatial_scores$random$experiment$display[, 1:10]), 10*nrow(spatial_scores$random$experiment$display), byrow= FALSE), 
                  sd_expLast10  = matrix(t(spatial_scores$random$experiment$display[, 21:30]), 10*nrow(spatial_scores$random$experiment$display), byrow= FALSE))

spatialdata = rbind(fscon, rscon)

# Set up summary data dataframe: spatial choice consistency
sc_a = setNames(aggregate(spatialdata$sc_practice, by=list(spatialdata$condition, spatialdata$subject), mean), c("condition", "subject", "avg"))
sc_b = setNames(aggregate(spatialdata$sc_expFirst10, by=list(spatialdata$condition, spatialdata$subject), mean), c("condition", "subject", "avg"))
sc_c = setNames(aggregate(spatialdata$sc_expLast10, by=list(spatialdata$condition, spatialdata$subject), mean), c("condition", "subject", "avg"))

avg_scdata = rbind(cbind(sc_a, phase=rep("untimed practice", nrow(sc_a))), 
                    cbind(sc_b, phase=rep("deadline early", nrow(sc_b))), 
                    cbind(sc_c, phase=rep("deadline late", nrow(sc_c))))
avg_scdata$phase = as.factor(avg_scdata$phase)         # Convert phase to factor
levels(avg_scdata$condition) = c("fixed", "random") # Replace condition names

# Set up summary data dataframe: spatial display consistency
sd_a = setNames(aggregate(spatialdata$sd_practice, by=list(spatialdata$condition, spatialdata$subject), mean), c("condition", "subject", "avg"))
sd_b = setNames(aggregate(spatialdata$sd_expFirst10, by=list(spatialdata$condition, spatialdata$subject), mean), c("condition", "subject", "avg"))
sd_c = setNames(aggregate(spatialdata$sd_expLast10, by=list(spatialdata$condition, spatialdata$subject), mean), c("condition", "subject", "avg"))

avg_sddata = rbind(cbind(sd_a, phase=rep("untimed practice", nrow(sd_a))), 
                    cbind(sd_b, phase=rep("deadline early", nrow(sd_b))), 
                    cbind(sd_c, phase=rep("deadline late", nrow(sd_c))))
avg_sddata$phase = as.factor(avg_sddata$phase)         # Convert phase to factor
levels(avg_sddata$condition) = c("fixed", "random") # Replace condition names

```

The following plot shows the distribution of distribution of participant's spatial strategy use. Higher proportions indicate responses which are more consistent with a spatial strategy. These figures indicate that when difficulty is maintained in a fixed location, two groups emerge under a deadline: those who do not use a spatial strategy and those who do use a spatial strategy. 

In the random difficulty condition, participants tend not to use a spatial strategy except later in the task where there is a deadline.

```{r plotSpatialData, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
spatial_choice_plot <- avg_scdata %>% ggplot(aes(x=avg, fill=phase)) + geom_histogram(color="white", alpha=0.6, bins = 10, position="identity") + facet_wrap(~condition+phase) + labs(y="Frequency", x = "Proportion of Spatially Consistent Responses") + ggtitle("Spatial Strategy Analysis")

#avg_plot <- avg_avgdata %>% ggplot(aes(x=avg, fill=phase+phase)) + geom_histogram(color="white", alpha=1, bins = 10) + facet_wrap(~condition+phase)

print(spatial_choice_plot)

```

Some other questions arise:

* TODO: What should be done with fixed location participants in which the optimal solution is also a circular strategy? Analyse the data again but removing trials in which difficulty is mapped in a circular manner?

