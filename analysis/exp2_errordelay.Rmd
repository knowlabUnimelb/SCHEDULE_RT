---
title: "Experiment 2: 4 RDKs with error delay"
author: "knowlabUnimelb"
date: "2020-11-24"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

Daniel R. Little^1^, Ami Eidels^2^, and Deborah J. Lin^1^


^1^ The University of Melbourne, ^2^ The University of Newcastle

```{r load_modules, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
rm(list=ls())
library(tidyverse)
library(workflowr)
#library(Rankcluster)
#library(rankdist) # Crashes rStudio
#library(Kendall)
library(DescTools) # ConDisPairs looks useful
library(gtools) 
library(english)
library(ggplot2)
library(dplyr)
library(hrbrthemes)
library(knitr)
library(reshape2)
library(png)
library(grid)
library(lme4)
library(rstatix)
library(jpeg)
```

```{r load_data, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Notes: 
# Uniqueid 25363 attempted the experiment three times, only finishing it the third time
# Somehow, the demographic line did not record on their third attempt; this fouls up the analysis which expects it
# I've added this line to the data. This can be safely accomplished because the uniqueid's are tied to their SONA account and the same sex and gender were already entered twice for the prior attempts

#define working directories
inputdir <- "data"

# Reading data and variable names 
fixed_datafilename = "exp2_fixed_rdk_delay_data.csv"
random_datafilename = "exp2_random_rdk_delay_data.csv"

colfile       <- read.csv(paste(inputdir,"data_dictionary.csv",sep="/"), stringsAsFactors = FALSE)
fixed_datafn  <- paste(inputdir,fixed_datafilename,sep="/") 
random_datafn <- paste(inputdir,random_datafilename,sep="/") 
fixd_rawdata  <- read.csv(fixed_datafn, header = FALSE, col.names = colfile$Column, stringsAsFactors = FALSE) # Add column labels to data
rand_rawdata    <- read.csv(random_datafn, header = FALSE, col.names = colfile$Column, stringsAsFactors = FALSE) # Add column labels to data

# Handful of subjects who partially completed the experiment without an id, remove them
fixd_rawdata$uniqueid = as.integer(fixd_rawdata$uniqueid)
rand_rawdata$uniqueid = as.integer(rand_rawdata$uniqueid)

fixd_rawdata = fixd_rawdata[!is.na(fixd_rawdata$uniqueid), ]
rand_rawdata = rand_rawdata[!is.na(rand_rawdata$uniqueid), ]

# Most columns need to be read in as characters to deal with the issue that there are missing NULL values, fix those here to avoid headaches later
fixd_rawdata$condition = as.factor(fixd_rawdata$condition)
levels(fixd_rawdata$condition) = c("fixed")
fixd_rawdata$trial_number = as.integer(fixd_rawdata$trial_number)
fixd_rawdata$trial_event = as.factor(fixd_rawdata$trial_event)
fixd_rawdata$button_pressed = as.integer(fixd_rawdata$button_pressed)
fixd_rawdata$rt = as.numeric(fixd_rawdata$rt) # -1's are rdks that were not completed, time outs
fixd_rawdata$dot_direction = as.integer(fixd_rawdata$dot_direction)
fixd_rawdata$dot_coherence = as.numeric(fixd_rawdata$dot_coherence)
fixd_rawdata$key_press = as.integer(fixd_rawdata$key_press) # -1's are rdks that were not completed, time outs
fixd_rawdata$trial_duration = as.numeric(fixd_rawdata$trial_duration)
fixd_rawdata$correct[fixd_rawdata$correct == ""] = "0" # Incorrect trials were recorded as ""
fixd_rawdata$correct = as.numeric(fixd_rawdata$correct)
fixd_rawdata$time_elapsed = as.numeric(fixd_rawdata$time_elapsed)
fixd_rawdata$patch_0 = as.numeric(fixd_rawdata$patch_0)
fixd_rawdata$patch_1 = as.numeric(fixd_rawdata$patch_1)
fixd_rawdata$patch_2 = as.numeric(fixd_rawdata$patch_2)
fixd_rawdata$patch_3 = as.numeric(fixd_rawdata$patch_3)

rand_rawdata$condition = as.factor(rand_rawdata$condition)
levels(rand_rawdata$condition) = c("random")
rand_rawdata$trial_number = as.integer(rand_rawdata$trial_number)
rand_rawdata$trial_event = as.factor(rand_rawdata$trial_event)
rand_rawdata$button_pressed = as.integer(rand_rawdata$button_pressed)
rand_rawdata$rt = as.numeric(rand_rawdata$rt) # -1's are rdks that were not completed, time outs
rand_rawdata$dot_direction = as.integer(rand_rawdata$dot_direction)
rand_rawdata$dot_coherence = as.numeric(rand_rawdata$dot_coherence)
rand_rawdata$key_press = as.integer(rand_rawdata$key_press) # -1's are rdks that were not completed, time outs
rand_rawdata$trial_duration = as.numeric(rand_rawdata$trial_duration)
rand_rawdata$correct[rand_rawdata$correct == ""] = "0" # Incorrect trials were recorded as ""
rand_rawdata$correct = as.numeric(rand_rawdata$correct)
rand_rawdata$time_elapsed = as.numeric(rand_rawdata$time_elapsed)
rand_rawdata$patch_0 = as.numeric(rand_rawdata$patch_0)
rand_rawdata$patch_1 = as.numeric(rand_rawdata$patch_1)
rand_rawdata$patch_2 = as.numeric(rand_rawdata$patch_2)
rand_rawdata$patch_3 = as.numeric(rand_rawdata$patch_3)

# Summary data
fixedLoggedSubjects  = unique(fixd_rawdata$uniqueid)  # Unique subject numbers
nFixedLoggedSubjects = length(fixedLoggedSubjects) # Number of subjects who logged into the website using the link

randomLoggedSubjects  = unique(rand_rawdata$uniqueid)   # Unique subject numbers
nRandomLoggedSubjects = length(randomLoggedSubjects) # Number of subjects who logged into the website using the link

```

```{r data_cleaning, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# A full data set has 10 practice trials (0 to 9) and 30 deadline trials (0 to 29)
# A full data set will have a max trial number of 29 
nTotalTrials = 29 # Counting from trial 0
cleanUpData = function(rawdata, nTotalTrials){
  
  completeSubjects = unique(rawdata$subject[which(rawdata$trial_number == nTotalTrials)]) # Unique subject ids, which removes NA's
  nCompleteSubjects = length(completeSubjects) # Nubmer of complete data files

  cleandata = rawdata[rawdata$subject %in% completeSubjects, ] # keep only complete data files
  # some subjects may have completed the experiment twice, keep only first completion
  subids = distinct(as.data.frame(cbind(cleandata$subject, cleandata$uniqueid)))
  names(subids) = c("subject", "uniqueid")
  
  # repeated uniqueids indicate duplicate completion
  nRepeats = sum(duplicated(subids$uniqueid))
  nonrepeatedsubs = subids$subject[which(!duplicated(subids$uniqueid))]
  
  # keep only nonrepeated subs
  data = cleandata[cleandata$subject %in% nonrepeatedsubs, ]
  
  # Summary data
  subjects = unique(data$uniqueid)           # Unique subject numbers
  nSubjects = length(unique(data$uniqueid))  # Number of subjects
  
  return(list("data"=data, "subjects"=subjects, "nSubjects"=nSubjects, "nRepeats"=nRepeats))
}

fd = cleanUpData(fixd_rawdata, nTotalTrials)
rd = cleanUpData(rand_rawdata, nTotalTrials)

```

```{r add_phase, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}

# Add in phase column which indicattzes whether current trials are practice or experiment
# Somehow, the demographic row for subject 25363 was removed
add_phase_col = function(data){
  data$data$phase = rep(NA, nrow(data$data))
  for (i in 1:data$nSubjects){
    
    # Find point at which trial_index = 0 later in the trial
    tidx = which(data$data$trial_number[data$data$uniqueid == data$subjects[i]] == 0)
    idx = tidx[which(diff(tidx) > 1) + 1]
    
    dsize = nrow(data$data[data$data$uniqueid == data$subjects[i], ])
    data$data$phase[data$data$uniqueid == data$subjects[i]] = c(NA, rep(0, idx-2), rep(1,length(idx:(dsize-1))), NA)
  }
  
  return(data)
}

fd = add_phase_col(fd)
rd = add_phase_col(rd)

```


```{r emails, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Need to extract emails for sending results from all datasets
# trial_event = email

data = rbind(fd$data, rd$data)

demographics = data$responses[data$trial_event == "demographics"]
#emails = demographics[grep("Email", demographics)]
#colon_loc = gregexpr(pattern = ":", emails)

nSubjects = fd$nSubjects+rd$nSubjects
#full_email_list = rep(NA, nSubjects)
#for (i in 1:nSubjects){
#  if (!is.na(emails[i])){
#    full_email_list[i] = substr(emails[i], colon_loc[[i]][1]+2, nchar(emails[i])-2)
#  }
#}
#email_list = str_sort(full_email_list[full_email_list != "" & !is.na(full_email_list)])

```

```{r demographics, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Demographics
# trial_event = sex_age
# responses --> Gender and Age
processDemographics = function(data, nSubjects){

  demographics = data$responses[data$trial_event == "demographics"]
  sexage = demographics[grep("Gender", demographics)]
  
  colon_loc = gregexpr(pattern = ":", sexage)
  comma_loc = gregexpr(pattern = ",", sexage)
  
  sex = rep(NA, nSubjects)
  age = rep(NA, nSubjects)
  for (i in 1:nSubjects){
    
    if (!is.na(sexage[i])){
    sex[i] = toupper(substr(sexage[i], colon_loc[[i]][1]+2, comma_loc[[i]][1]-2))

    
    
    x = substr(sexage[i], colon_loc[[i]][2]+2, nchar(sexage[i])-2)
    if (nchar(x) == 2){
      age[i] = as.numeric(x)
    } else {
      age[i] = as.numeric(substr(sexage[i], colon_loc[[i]][2]+2, colon_loc[[i]][2]+4))    
    }
    
    } else {
      sex[i] = "NIL"
    }
  }
  
  nFemales = sum(sex == "FEMALE" | sex == "WOMEN" | sex == "F")
  nMales = sum(sex == "MALE" | sex == "M")
  nOther = sum(sex != "FEMALE" & sex != "MALE" & sex != "WOMEN" & sex != "M" & sex != "F")
  
  meanAge = mean(age, na.rm = TRUE)
  stdAge  = sd(age, na.rm = TRUE)
  
  return(list(nFemales, nMales, nOther, meanAge, stdAge, age))
}

fixedDemo = processDemographics(fd$data, fd$nSubjects)
names(fixedDemo) = c("nFemales", "nMales", "nOthers", "meanAge", "stdAge", "ages")
randDemo = processDemographics(rd$data, rd$nSubjects)
names(randDemo) = c("nFemales", "nMales", "nOthers", "meanAge", "stdAge", "ages")

```
In Experiment 1, where there was no time penalty applied for making an incorrect RDK judgment, it was possible for subjects to adopt a "fast guess" strategy, particularly when responding to the hardest RDK's. Although our analysis of RT and reward rate suggested that this was not the case, we sought to further mitigate against this strategy by imposing a 500 msec time penalty after an error response. Experiment 2 thus acts as a conceptual replication of Experiment 1 but with an additional error penalty. 

# Method

## Participants

We tested `r fd$nSubjects + rd$nSubjects` participants (`r fixedDemo$nFemales+randDemo$nFemales` F, `r fixedDemo$nMales+randDemo$nMales` M, `r fixedDemo$nOthers+randDemo$nOthers` Undeclared). Participants were recruited through the Melbourne School of Psychological Sciences Research Experience Pool (Mean age = `r round(mean(c(fixedDemo$ages, randDemo$ages), na.rm=TRUE),2) `, range = `r min(c(fixedDemo$ages, randDemo$ages), na.rm=TRUE) ` - `r max(c(fixedDemo$ages, randDemo$ages), na.rm=TRUE)`) and  were reimbursed with credit toward completion of a first year psychology subject. Datasets from `r fd$nRepeats + rd$nRepeats` subjects were excluded for completing the experiment twice; i.e., only the first of the datasets for these subjects was retained.

`r paste(toupper(substring(english(fd$nSubjects), 1, 1)), substring(english(fd$nSubjects), 2), sep="")` were assigned to the _Fixed Difficulty_ condition. In this condition, the location of easy, medium, hard, and very hard random dot kinematograms (RDK's) was held constant across trials. 

`r paste(toupper(substring(english(rd$nSubjects), 1, 1)), substring(english(rd$nSubjects), 2), sep="")` were assigned to the _Random Difficulty_ condition. In this condition, the location of easy, medium, hard, and very hard random dot kinematograms (RDK's) were randomized from trial to trial. 

The Fixed Difficulty experiment was completed before the Random Difficulty experiment. Participants only completed one of these.


## Design

```{r getCoherence, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
coherence_set = sort(unique(c(data$patch_0, data$patch_1, data$patch_2, data$patch_3)), decreasing = TRUE)
```

The design of the experiment was identical to Experiment 1, with the sole exception being that after making an error on an RDK direction judgment, a blank interval was presented for 500 msec before the RDK was resampled, and the RDK trial began again. 

_Data Cleaning_

```{r analyse_RDK_difficulty, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
rdk = data[data$trial_event == "rdk", ]

# Make phase a factor
rdk$phase = as.factor(rdk$phase)
levels(rdk$phase) = c("no_deadline", "deadline")

# Analyse rdk timeouts
nTimeouts = sum(rdk$rt == -1)
pTimeouts = sum(rdk$rt == -1)/nrow(rdk)
timeoutsPerSubject = aggregate(list("timeouts" = rdk$rt == -1), by=list("subject"=rdk$uniqueid), FUN = sum)
avgTimeoutPerSubject = mean(timeoutsPerSubject$timeouts)

# Remove rdk timeouts
rdk = rdk[rdk$rt != -1, ]

# Analyse long rts
nlongrts.no_deadline = sum(rdk$rt[rdk$phase == "no deadline"] > 3000)
nlongrts.deadline = sum(rdk$rt[rdk$phase == "deadline"] > 3000)

# Remove long rts
rdk = rdk[rdk$rt < 3000, ]

```

```{r identify_nonlearners, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
rdk.easyacc = aggregate(rdk$correct[rdk$dot_coherence == .8], by=list("condition" = rdk$condition[rdk$dot_coherence == .8], "phase" = rdk$phase[rdk$dot_coherence == .8], "subject" = rdk$uniqueid[rdk$dot_coherence == .8]), FUN=mean)

nonlearners = unique(rdk.easyacc$subject[rdk.easyacc$x < .4])
nNonlearners = length(nonlearners)

# Remove nonlearners
data = data[!(data$uniqueid %in% nonlearners), ]
rdk = rdk[!(rdk$uniqueid %in% nonlearners), ]
n = distinct(as.data.frame(cbind("condition" = data$condition, "subject" = data$uniqueid)))  %>% count(condition)

# Update subjects counts
nRemainingFixed = n$n[n$condition == 1]
nRemainingRandom = n$n[n$condition == 2]


```

`r nNonlearners` subjects had less than chance accuracy on the easiest RDK; we removed these participants from further anlaysis leaving `r nRemainingFixed` and `r nRemainingRandom` in the fixed and random location conditions, respectively.

```{r task_completion, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
tcdata = aggregate(rdk$trial_event[rdk$correct == 1], by=list("condition" = rdk$condition[rdk$correct == 1], "trial" = rdk$trial_number[rdk$correct == 1], "phase" = rdk$phase[rdk$correct == 1], "subject" = rdk$uniqueid[rdk$correct == 1]), FUN=length)

avgCompletions = aggregate(list("M" = tcdata$x), by=list("Phase"=tcdata$phase, "Condition"=tcdata$condition), FUN=mean)

```

# Data Analysis

## Task completions

* How many tasks are completed on average?

Across both conditions, participants completed `r round(mean(avgCompletions$M[avgCompletions$Phase == "no_deadline"]),2)` tasks during the `r as.character(avgCompletions$Phase[1])` phase and `r round(mean(avgCompletions$M[avgCompletions$Phase == "deadline"]),2)` tasks during the `r as.character(avgCompletions$Phase[2])` phase. 

```{r task_completion_table, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# Reorder columns
avgCompletions = avgCompletions[c("Condition", "Phase", "M")]
avgCompletions$M = round(avgCompletions$M, 2)

kable(avgCompletions, caption="Average number of correctly completed tasks in each condition")
```

```{r task_completion_anova, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}

tc.aov = aov(x ~ condition + phase + condition:phase, data = tcdata)
tc.ml0 = lm(x ~ condition + phase + condition:phase, data = tcdata)
tc.ml1 = lmer(x ~ condition + phase + condition:phase + (1|subject), data = tcdata)
tc.ml2 = lmer(x ~ condition + phase + condition:phase + (1+phase|subject), data = tcdata)

compare.1 = anova(tc.ml1, tc.ml0, test="chisq")
compare.2 = anova(tc.ml2, tc.ml1, test="chisq")

# Comparison indicates that tc.ml2 is the preferred model on a BIC basis

tc.ml2.summary = summary(tc.ml2)

```

There were fewer tasks completed under a deadline than without a deadline ($\beta_{deadline}$ = `r round(abs(tc.ml2.summary$coefficients[rownames(tc.ml2.summary$coefficients) == "phasedeadline", colnames(tc.ml2.summary$coefficients) == "Estimate"]), 2)`, SE =  `r round(abs(tc.ml2.summary$coefficients[rownames(tc.ml2.summary$coefficients) == "phasedeadline", colnames(tc.ml2.summary$coefficients) == "Std. Error"]), 2)`).[^1] There was no difference between conditions, ($\beta_{condition}$ = `r round(abs(tc.ml2.summary$coefficients[rownames(tc.ml2.summary$coefficients) == "conditionrandom", colnames(tc.ml2.summary$coefficients) == "Estimate"]), 2)`, SE =  `r round(abs(tc.ml2.summary$coefficients[rownames(tc.ml2.summary$coefficients) == "conditionrandom", colnames(tc.ml2.summary$coefficients) == "Std. Error"]), 2)`). As shown in the table, there was an interaction between deadline and location condition ($\beta_{condition \times deadline}$= `r round(abs(tc.ml2.summary$coefficients[rownames(tc.ml2.summary$coefficients) == "conditionrandom:phasedeadline", colnames(tc.ml2.summary$coefficients) == "Estimate"]), 2)`, SE =  `r round(abs(tc.ml2.summary$coefficients[rownames(tc.ml2.summary$coefficients) == "conditionrandom:phasedeadline", colnames(tc.ml2.summary$coefficients) == "Std. Error"]), 2)`), with deadline affecting the number of completed tasks in the random condition more than in the fixed condition. [^2]

[^1]: Throughout, we infer significance by examining whether 2 \(\times\) SE includes 0.

[^2]: We compared three models: (1) a standard linear regression model with location condition, deadline, and their interaction as factors (BIC = `r round(compare.1$BIC[1], 2)`) ; (2) a multilevel regression model with an additional random intercept for each subject (BIC = `r round(compare.1$BIC[2], 2)`); and (3) a multilevel regression with a random intercept and random deadline coefficient for each subject (BIC = `r round(compare.2$BIC[2], 2)`). The third model was preferred on a BIC basis; hence, we report the details of that model only.

## RDK performance

```{r rdk_anova, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
aov.acc.data = aggregate(list("accuracy" = rdk$correct), by = list("subject" = rdk$uniqueid, "condition" = rdk$condition, "phase" = rdk$phase, "difficulty" = rdk$dot_coherence), FUN = function(x) mean(x, na.rm=TRUE))

aov.rt.data = aggregate(list("rt" = rdk$rt), by = list("subject" = rdk$subject, "condition" = rdk$condition, "phase" = rdk$phase, "difficulty" = rdk$dot_coherence), FUN = function(x) mean(x, na.rm=TRUE))

# Note that RT is computed by averaging every attempt
# Another way to compute RT is by summing over incorrect attempts until the RDK is responded to correctly

rdk.sumrt = aggregate(list("sumrt" = rdk$rt), by = list("subject"=rdk$subject, "condition"=rdk$condition, "phase"=rdk$phase, "difficulty"=rdk$dot_coherence, "trial"=rdk$trial_number), FUN = function(x) tail(cumsum(x), n=1)+((length(x)-1) * 500))

rdk.sumrt = rdk.sumrt[rdk.sumrt$sumrt <= 6000, ]

aov.sumrt.data = aggregate(list("rt" = rdk.sumrt$sumrt), by = list("subject" = rdk.sumrt$subject, "condition" = rdk.sumrt$condition, "phase" = rdk.sumrt$phase, "difficulty" = rdk.sumrt$difficulty), FUN = function(x) mean(x, na.rm=TRUE))

#anova.acc = glm(accuracy ~ condition + phase + difficulty + condition:phase:difficulty, aov.acc.data, family = "gaussian")
#anova.rt = glm(rt ~ condition + phase + difficulty + condition:phase:difficulty, aov.rt.data, family = "gaussian")

anova.acc = anova_test(data = aov.acc.data, dv = accuracy, wid = subject, within = c(phase, difficulty), between = condition)
anova.rt = anova_test(data = aov.rt.data, dv = rt, wid = subject, within = c(phase, difficulty), between = condition)
anova.sumrt = anova_test(data = aov.sumrt.data, dv = rt, wid = subject, within = c(phase, difficulty), between = condition)

```

* What was the average completion time and accuracy of the easy, medium, hard, and very hard tasks? 

RTs became shorter and more accurate as the difficulty of the RDK became easier. As expected, the RTs were shorter under a deadline than without a deadline. For the first plot, showing the average of each attempt on each RDK, we first removed trials with RTs greater than 3000 msec (N = `r nlongrts.no_deadline + nlongrts.deadline`). 

```{r difficulty_plot, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# Difficulty plot
rdk$dot_coherence = as.factor(rdk$dot_coherence)
levels(rdk$dot_coherence) = c("very hard", "hard", "medium", "easy")

diff_plot <- rdk %>% ggplot(aes(x=dot_coherence, y=rt, fill=dot_coherence)) + geom_violin(adjust = 1.5, trim = TRUE) + facet_wrap(~phase) + labs(y="RT (msec)", x = "Difficulty")

print(diff_plot + ggtitle("Response times as a function of difficulty"))
```

For the second plot, showing the time to complete an RDK as the cumulative sum across multiple attempts within a trial. We removed trials with RTs greater than 6000 msec. This plot reflects the total time to complete the RDK correctly, including any error penalties. 

```{r difficulty_sum_plot, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# RT summed over additional attempts
rdk.sumrt$difficulty = as.factor(rdk.sumrt$difficulty)
levels(rdk.sumrt$difficulty) = c("very hard", "hard", "medium", "easy")

sumdiff_plot <- rdk.sumrt %>% ggplot(aes(x=difficulty, y=sumrt, fill=difficulty)) + geom_violin(adjust = 1.5, trim = TRUE) + facet_wrap(~phase) + labs(y="RT (msec)", x = "Difficulty")

print(sumdiff_plot + ggtitle("Response times summed over attempts as a function of difficulty"))

```

We further broke down RTs by condition, deadline, and difficulty. 

```{r difficulty_data, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}

# Find average rdk accuracy and rt in each codnition, phase, and coherence level
difficulty = aggregate(list("accuracy" = rdk$correct, "rt" = rdk$rt), by = list("difficulty" =        rdk$dot_coherence, "phase" = rdk$phase, "condition" = rdk$condition), FUN = function(x) mean(x, na.rm = TRUE))

sum_difficulty = aggregate(list("sumrt" = rdk.sumrt$sumrt), by = list("difficulty" = rdk.sumrt$difficulty, "phase" = rdk.sumrt$phase, "condition" = rdk.sumrt$condition), FUN = function(x) mean(x, na.rm = TRUE))
                
diffsd = aggregate(list("accuracy" = rdk$correct, "rt" = rdk$rt), by = list("difficulty" =        rdk$dot_coherence, "phase" = rdk$phase, "condition" = rdk$condition), FUN = function(x) sd(x, na.rm = TRUE))

sum_diffsd = aggregate(list("sumrt" = rdk.sumrt$sumrt), by = list("difficulty" =  rdk.sumrt$difficulty, "phase" = rdk.sumrt$phase, "condition" = rdk.sumrt$condition), FUN = function(x) sd(x, na.rm = TRUE))

ncounts = rdk %>% count(condition, phase, dot_coherence)
difficulty$n = ncounts$n
difficulty$accuracy = round(difficulty$accuracy, 2)
difficulty$rt = round(difficulty$rt, 2)
difficulty$se.acc = diffsd$accuracy/sqrt(difficulty$n)
difficulty$se.acc = round(difficulty$se.acc, 2)
difficulty$se.rt = diffsd$rt/sqrt(difficulty$n)
difficulty$se.rt = round(difficulty$se.rt, 2)

difficulty$sumrt = round(sum_difficulty$sumrt, 2)
difficulty$se.sumrt = sum_diffsd$sumrt/sqrt(difficulty$n)
difficulty$se.sumrt = round(difficulty$se.sumrt, 2)

# Get reward rate standard error
rrdata = aggregate(list("accuracy" = rdk$correct), by = list("difficulty" =        rdk$dot_coherence, "phase" = rdk$phase, "condition" = rdk$condition, "subject"=rdk$subject), FUN = function(x) mean(x, na.rm = TRUE))
rrdata_sumrt = aggregate(list("sumrt" = rdk.sumrt$sumrt), by = list("difficulty" = rdk.sumrt$difficulty, "phase" = rdk.sumrt$phase, "condition" = rdk.sumrt$condition, "subject"=rdk.sumrt$subject), FUN = function(x) mean(x, na.rm = TRUE))


rrdata$sumrt = rrdata_sumrt$sumrt
rrdata$rewardRate = rrdata$accuracy/(rrdata$sumrt/1000)

subRewardRate = aggregate(list("rr" = rrdata$rewardRate), by = list("difficulty" =  rrdata$difficulty, "phase" = rrdata$phase, "condition" = rrdata$condition), FUN = function(x) mean(x, na.rm = TRUE))

subRewardRate.se = aggregate(list("rr" = rrdata$rewardRate), by = list("difficulty" =  rrdata$difficulty, "phase" = rrdata$phase, "condition" = rrdata$condition), FUN = function(x) sd(x, na.rm = TRUE))

difficulty$rewardRate = subRewardRate$rr
difficulty$SE.rewardRate = subRewardRate.se$rr/sqrt(difficulty$n)


difficulty$difficulty = as.factor(difficulty$difficulty)
levels(difficulty$difficulty) = c("Very Hard", "Hard", "Medium", "Easy")
```


```{r difficulty_table, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# Create the table
difficulty = difficulty[c("condition", "phase", "difficulty", "n", "accuracy", "se.acc", "rt", "se.rt", "sumrt", "se.sumrt")]
colnames(difficulty)[colnames(difficulty) == "accuracy"] = "Mean.Correct"
colnames(difficulty)[colnames(difficulty) == "se.acc"] = "SE.Correct"
colnames(difficulty)[colnames(difficulty) == "rt"] = "Mean.RT"
colnames(difficulty)[colnames(difficulty) == "se.rt"] = "SE.RT"
colnames(difficulty)[colnames(difficulty) == "sumrt"] = "Mean.SumRT"
colnames(difficulty)[colnames(difficulty) == "se.sumrt"] = "SE.SumRT"
knitr::kable(difficulty, caption="Mean accuracy, RT, and RT summed across attempts for each difficulty and each phase")

# Marginal means
# aggregate(rdk$correct, by=list(rdk$condition), FUN=mean)
# aggregate(rdk$correct, by=list(rdk$phase), FUN=mean)
# aggregate(rdk$correct, by=list(rdk$difficulty), FUN=mean)
```

Statistical analysis, using a 2 condition $\times$ 2 phase $\times$ 4 difficulty between-within ANOVA, of the effect of these factors on accuracy confirmed the effect of difficulty, F(`r anova.acc$ANOVA$DFn[anova.acc$ANOVA$Effect == "difficulty"]`, `r anova.acc$ANOVA$DFd[anova.acc$ANOVA$Effect == "difficulty"]`) = `r round(anova.acc$ANOVA$F[anova.acc$ANOVA$Effect == "difficulty"], 2)`, p = `r round(anova.acc$ANOVA$p[anova.acc$ANOVA$Effect == "difficulty"],2)`, $\eta^2$ = `r round(anova.acc$ANOVA$ges[anova.acc$ANOVA$Effect == "difficulty"], 2)`. RDK responses in the fixed condition were more accurate than RDK responses in the random condition, F(`r anova.acc$ANOVA$DFn[anova.acc$ANOVA$Effect == "condition"]`, `r anova.acc$ANOVA$DFd[anova.acc$ANOVA$Effect == "condition"]`) = `r round(anova.acc$ANOVA$F[anova.acc$ANOVA$Effect == "condition"], 2)`, p = `r round(anova.acc$ANOVA$p[anova.acc$ANOVA$Effect == "condition"],2)`, $\eta^2$ = `r round(anova.acc$ANOVA$ges[anova.acc$ANOVA$Effect == "condition"], 2)`. RDK responses were not more accurate under a deadline then under no deadline, F(`r anova.acc$ANOVA$DFn[anova.acc$ANOVA$Effect == "phase"]`, `r anova.acc$ANOVA$DFd[anova.acc$ANOVA$Effect == "phase"]`) = `r round(anova.acc$ANOVA$F[anova.acc$ANOVA$Effect == "phase"], 2)`, p = `r round(anova.acc$ANOVA$p[anova.acc$ANOVA$Effect == "phase"],2)`, $\eta^2$ = `r round(anova.acc$ANOVA$ges[anova.acc$ANOVA$Effect == "phase"], 2)`. Finally, unlike Experiment 1, there was no phase $\times$ difficulty interaction, F(`r anova.acc$ANOVA$DFn[anova.acc$ANOVA$Effect == "phase:difficulty"]`, `r anova.acc$ANOVA$DFd[anova.acc$ANOVA$Effect == "phase:difficulty"]`) = `r round(anova.acc$ANOVA$F[anova.acc$ANOVA$Effect == "phase:difficulty"], 2)`, p = `r round(anova.acc$ANOVA$p[anova.acc$ANOVA$Effect == "phase:difficulty"],2)`, $\eta^2$ = `r round(anova.acc$ANOVA$ges[anova.acc$ANOVA$Effect == "phase:difficulty"], 2)` reflecting a greater increase from easy to very hard when there was no deadline compared to when there was a deadline.

RTs were shorter under a deadline, F(`r anova.rt$ANOVA$DFn[anova.rt$ANOVA$Effect == "phase"]`, `r anova.rt$ANOVA$DFd[anova.rt$ANOVA$Effect == "phase"]`) = `r round(anova.rt$ANOVA$F[anova.rt$ANOVA$Effect == "phase"], 2)`, p = `r round(anova.rt$ANOVA$p[anova.rt$ANOVA$Effect == "phase"],2)`, $\eta^2$ = `r round(anova.rt$ANOVA$ges[anova.rt$ANOVA$Effect == "phase"], 2)`, and that RTs became shorter as the RDK's became easier, F(`r anova.rt$ANOVA$DFn[anova.rt$ANOVA$Effect == "difficulty"]`, `r anova.rt$ANOVA$DFd[anova.rt$ANOVA$Effect == "difficulty"]`) = `r round(anova.rt$ANOVA$F[anova.rt$ANOVA$Effect == "difficulty"], 2)`, p = `r round(anova.rt$ANOVA$p[anova.rt$ANOVA$Effect == "difficulty"],2)`, $\eta^2$ = `r round(anova.rt$ANOVA$ges[anova.rt$ANOVA$Effect == "difficulty"], 2)`. There was again an interaction between phase and difficulty, F(`r anova.rt$ANOVA$DFn[anova.rt$ANOVA$Effect == "phase:difficulty"]`, `r anova.rt$ANOVA$DFd[anova.rt$ANOVA$Effect == "phase:difficulty"]`) = `r round(anova.rt$ANOVA$F[anova.rt$ANOVA$Effect == "phase:difficulty"], 2)`, p = `r round(anova.rt$ANOVA$p[anova.rt$ANOVA$Effect == "phase:difficulty"],2)`, $\eta^2$ = `r round(anova.rt$ANOVA$ges[anova.rt$ANOVA$Effect == "phase:difficulty"], 2)` indicating that RT decreased more with increasing dot coherence when there was no deadline compared to when there was a deadline. The pattern of these results replicated Experiment 1. 

In analysing sumRT, we confirmed that sumRTs were shorter under a deadline, F(`r anova.sumrt$ANOVA$DFn[anova.sumrt$ANOVA$Effect == "phase"]`, `r anova.sumrt$ANOVA$DFd[anova.sumrt$ANOVA$Effect == "phase"]`) = `r round(anova.sumrt$ANOVA$F[anova.sumrt$ANOVA$Effect == "phase"], 2)`, p = `r round(anova.sumrt$ANOVA$p[anova.sumrt$ANOVA$Effect == "phase"],2)`, $\eta^2$ = `r round(anova.sumrt$ANOVA$ges[anova.sumrt$ANOVA$Effect == "phase"], 2)`, and that RTs became shorter as the RDK's became easier, F(`r anova.sumrt$ANOVA$DFn[anova.sumrt$ANOVA$Effect == "difficulty"]`, `r anova.sumrt$ANOVA$DFd[anova.sumrt$ANOVA$Effect == "difficulty"]`) = `r round(anova.sumrt$ANOVA$F[anova.sumrt$ANOVA$Effect == "difficulty"], 2)`, p = `r round(anova.sumrt$ANOVA$p[anova.sumrt$ANOVA$Effect == "difficulty"],2)`, $\eta^2$ = `r round(anova.sumrt$ANOVA$ges[anova.sumrt$ANOVA$Effect == "difficulty"], 2)`. There was again an interaction between phase and difficulty, F(`r anova.sumrt$ANOVA$DFn[anova.sumrt$ANOVA$Effect == "phase:difficulty"]`, `r anova.sumrt$ANOVA$DFd[anova.sumrt$ANOVA$Effect == "phase:difficulty"]`) = `r round(anova.sumrt$ANOVA$F[anova.sumrt$ANOVA$Effect == "phase:difficulty"], 2)`, p = `r round(anova.sumrt$ANOVA$p[anova.sumrt$ANOVA$Effect == "phase:difficulty"],2)`, $\eta^2$ = `r round(anova.sumrt$ANOVA$ges[anova.sumrt$ANOVA$Effect == "phase:difficulty"], 2)` indicating that RT decreased more with increasing dot coherence when there was no deadline compared to when there was a deadline. 

## Reward Rate

We again computed the reward rate to test whether our ordering of Easy to Very Hard reflected an optimal order. For Experiment 2, the computation of reward rate now includes the 500 msec penalty after each incorrect RDK response. 

Inspection of the figure reveals that RR is roughly monotonically increasing when tasks become easier in all conditions. Again, under such conditions, the optimal order of task-completion should be easy-to-hardest.


```{r rewardRate_plot, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
rr_plot <- rrdata %>% ggplot(aes(x=difficulty, y=rewardRate, fill=difficulty)) + geom_violin(adjust = 1.5, trim = TRUE) +  stat_summary(fun=mean, geom="point", shape=23, size=2) + facet_wrap(~phase+condition) + labs(y="Reward Rate = p(Correct)/RT(sec)", x = "Difficulty") + lims(y = c(0, 2.5))

print(rr_plot + ggtitle("Reward Rate as a function of difficulty"))


```


## Optimality in each condition

```{r distcomp, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
n = 4 # Number of tasks

# Distance parameters
maxdistance = (n * (n-1))/2
missing_penalty = maxdistance/n
allperms = permutations(n=4, r=4, v=1:4, repeats.allowed=FALSE)
nperms = nrow(allperms)

# Processing functions
splitData = function(data){
  pracdata = data[data$trial_event == "practice_rdk", ]
  exp_data = data[data$trial_event == "select_rdk", ]
  return(list("practice" = pracdata, "experiment" = exp_data))
}

# Compute distance from optimal for all perms
opt_order_set = function(trial_optimal_order, nperms=nperms, allperms=allperms){
  pdist <- rep(NA, nperms)
  for (i in 1:nperms){
    distObj = ConDisPairs(table(allperms[i, ], trial_optimal_order$ix))
    pdist[i] = distObj$D  
  }
  return(pdist)
}
# Usage: opt_order_set(poptimal_order[[1]], nperms, allperms)

# Compute distance from optimal for each trial during practice
get_trial_scores = function(sdata, ntrials, n, nperms, allperms, nSubjects, subjects){

  # preallocate variables for output
  max_distances <- matrix(data=NA, nrow=nSubjects, ncol=ntrials)
  min_distances <- matrix(data=NA, nrow=nSubjects, ncol=ntrials)
  avg_distances <- matrix(data=NA, nrow=nSubjects, ncol=ntrials)
  count_matrix = matrix(0,length(coherence_set),length(coherence_set))
  
  for (j in 1:nSubjects){
        # select out data for subject j
        tdata = sdata[sdata$uniqueid == subjects[j], ]
        
        # preallocated subject specific task selection matrix
        selmat <- matrix(data=NA, nrow=ntrials, ncol=n)
        optorder <- matrix(data=NA, nrow=ntrials, ncol=n)
        difforder <- matrix(data=NA, nrow=ntrials, ncol=n)
    for (i in 1:ntrials){
        
        # Get the task selection order for the current trial (may be incomplete if timed out)
        csel = tdata[tdata$trial_number == i-1, ]$button_pressed
        selmat[i, 1:length(csel)] = csel+1 # NULL is coded as option 5
        #selmat[i, selmat[i,] == 5] = NA  # Replace NULL with NA
        
        # Get the locations of easy, med, hard, etc
        patch_order = c(unique(tdata[tdata$trial_number == i-1, ]$patch_0), unique(tdata[tdata$trial_number == i-1, ]$patch_1), unique(tdata[tdata$trial_number == i-1, ]$patch_2), unique(tdata[tdata$trial_number == i-1, ]$patch_3))
        
        # Find the order in which easy, med, hard, etc were selected
        difforder[i,] = patch_order[selmat[i,]]
        
        for (k in 1:n){
          count_matrix[which(difforder[i,] == coherence_set[k]), k] = count_matrix[which(difforder[i,] == coherence_set[k]), k] + 1
        }
        
        # Get the optimal order
        order_to_compare = sort(patch_order, decreasing=TRUE, index.return = TRUE)
        optorder[i, ] = order_to_compare$ix
        
        # compute distances of all permutations to indicated order
        pdist = opt_order_set(order_to_compare, nperms, allperms)
        
        # Find permutation partial matches
        if (!all(is.na(selmat[i,]))){
          partial_perms = allperms[apply(do.call("rbind", rep(list(selmat[i,1:sum(!is.na(selmat[i,]))]), nperms)) == allperms[, !is.na(selmat[i,])], 1, function(x)all(x)), ]
        
          # Find distances consistent with partial matches
          partial_distances = pdist[apply(do.call("rbind", rep(list(selmat[i,1:sum(!is.na(selmat[i,]))]), nperms)) == allperms[, !is.na(selmat[i,])], 1, function(x)all(x))]
        } else {
          partial_distances = pdist
        }
        
        # Outputs
        max_distances[j,i] = max(partial_distances)  # Maximum distance of partial matches
        min_distances[j,i] = min(partial_distances)  # Maximum distance of partial matches
        avg_distances[j,i] = mean(partial_distances) # Average distance of partial matches
        
        
    }
    
    # Create better organised matrix of selections    
    if (j == 1){
      fullmat = cbind(rep(subjects[j], ntrials), selmat)
      fullopt = cbind(rep(subjects[j], ntrials), optorder)
      fulldiff = cbind(rep(subjects[j], ntrials), difforder)
    } else {
      fullmat = rbind(fullmat, cbind(rep(subjects[j], ntrials), selmat))
      fullopt = rbind(fullopt, cbind(rep(subjects[j], ntrials), optorder))
      fulldiff = rbind(fulldiff, cbind(rep(subjects[j], ntrials), difforder))
    }    
  }

  # Compute matches by subject for first selection, first two selections, first three selections
  match1 = aggregate(cbind(fullmat[,1], fullmat[,2]==fullopt[,2]), by=list(fullmat[,1]), FUN = function(x)mean(x,na.rm=TRUE))
  match2 = aggregate(cbind(fullmat[, 1], apply(fullmat[,2:3] == fullopt[,2:3], 1, all)), by=list(fullmat[,1]), FUN = function(x)mean(x,na.rm=TRUE))
  match3 = aggregate(cbind(fullmat[, 1], apply(fullmat[,2:4] == fullopt[,2:4], 1, all)), by=list(fullmat[,1]), FUN = function(x)mean(x,na.rm=TRUE))
  # match4 = aggregate(cbind(fullmat[, 1], apply(fullmat[,2:5] == fullopt[,2:5], 1, all)), by=list(fullmat[,1]), FUN = mean) # same as match3
  matches = as.data.frame(cbind(match1$V1, match1$V2, match2$V2, match3$V2))
  names(matches) = c("subjects", "match1", "match2", "match3")
  
  return(list("selections" = fullmat, "optimal_orders" = fullopt, "diff_orders" = fulldiff, "selection_counts" = count_matrix, "matches" = matches, "max_distances" = max_distances, "min_distances" = min_distances, "avg_distances" = avg_distances))
}

# Compute distances for condition x practice/experiment
# sdata, order_to_compare, ntrials, n, nperms, allperms, nSubjects, subjects
# sdata = splitData(rd$data)$practice
#  ntrials = 10
# nSubjects =rd$nSubjects
# subjects = rd$subjects
scores = list("fixed" = list("practice" = get_trial_scores(splitData(fd$data)$practice, 10, 
                                                           n, nperms, allperms, fd$nSubjects, fd$subjects), 
                             "experiment" = get_trial_scores(splitData(fd$data)$experiment, 30, 
                                                           n, nperms, allperms, fd$nSubjects, fd$subjects)), 
              "random" = list("practice" = get_trial_scores(splitData(rd$data)$practice, 10, 
                                                           n, nperms, allperms, rd$nSubjects, rd$subjects), 
                              "experiment" = get_trial_scores(splitData(rd$data)$experiment, 30, 
                                                           n, nperms, allperms, rd$nSubjects, rd$subjects)))


```


```{r buildComparison, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
fcon = data.frame(condition = as.factor(rep(1, fd$nSubjects*10)), 
                  subjects = rep(1:fd$nSubjects + 100, each=10), 
                  trials = rep(1:10, fd$nSubjects), 
                  max_practice = matrix(t(scores$fixed$practice$max_distances), 10*nrow(scores$fixed$practice$max_distances), byrow= FALSE), 
                  max_expFirst10 = matrix(t(scores$fixed$experiment$max_distances[, 1:10]), 10*nrow(scores$fixed$experiment$max_distances), byrow= FALSE), 
                  max_expLast10 = matrix(t(scores$fixed$experiment$max_distances[, 21:30]), 10*nrow(scores$fixed$experiment$max_distances), byrow= FALSE), 
                  min_practice = matrix(t(scores$fixed$practice$min_distances), 10*nrow(scores$fixed$practice$min_distances), byrow= FALSE), 
                  min_expFirst10 = matrix(t(scores$fixed$experiment$min_distances[, 1:10]), 10*nrow(scores$fixed$experiment$min_distances), byrow= FALSE), 
                  min_expLast10 = matrix(t(scores$fixed$experiment$min_distances[, 21:30]), 10*nrow(scores$fixed$experiment$min_distances), byrow= FALSE),                   
                  avg_practice = matrix(t(scores$fixed$practice$avg_distances), 10*nrow(scores$fixed$practice$avg_distances), byrow= FALSE), 
                  avg_expFirst10 = matrix(t(scores$fixed$experiment$avg_distances[, 1:10]), 10*nrow(scores$fixed$experiment$max_distances), byrow= FALSE), 
                  avg_expLast10  = matrix(t(scores$fixed$experiment$avg_distances[, 21:30]), 10*nrow(scores$fixed$experiment$max_distances), byrow= FALSE))

rcon = data.frame(condition = as.factor(rep(2, rd$nSubjects*10)), 
                  subjects = rep(1:rd$nSubjects + 200, each=10), 
                  trials = rep(1:10, rd$nSubjects), 
                  max_practice = matrix(t(scores$random$practice$max_distances), 10*nrow(scores$random$practice$max_distances), byrow= FALSE), 
                  max_expFirst10 = matrix(t(scores$random$experiment$max_distances[, 1:10]), 10*nrow(scores$random$experiment$max_distances), byrow= FALSE), 
                  max_expLast10 = matrix(t(scores$random$experiment$max_distances[, 21:30]), 10*nrow(scores$random$experiment$max_distances), byrow= FALSE), 
                  min_practice = matrix(t(scores$random$practice$min_distances), 10*nrow(scores$random$practice$min_distances), byrow= FALSE), 
                  min_expFirst10 = matrix(t(scores$random$experiment$min_distances[, 1:10]), 10*nrow(scores$random$experiment$min_distances), byrow= FALSE), 
                  min_expLast10 = matrix(t(scores$random$experiment$min_distances[, 21:30]), 10*nrow(scores$random$experiment$min_distances), byrow= FALSE),                   
                  avg_practice = matrix(t(scores$random$practice$avg_distances), 10*nrow(scores$random$practice$avg_distances), byrow= FALSE), 
                  avg_expFirst10 = matrix(t(scores$random$experiment$avg_distances[, 1:10]), 10*nrow(scores$random$experiment$max_distances), byrow= FALSE), 
                  avg_expLast10  = matrix(t(scores$random$experiment$avg_distances[, 21:30]), 10*nrow(scores$random$experiment$max_distances), byrow= FALSE))

expdata = rbind(fcon, rcon)

# Set up summary data dataframe: maximum partial completion efficiency
max_a = setNames(aggregate(expdata$max_practice, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))
max_b = setNames(aggregate(expdata$max_expFirst10, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))
max_c = setNames(aggregate(expdata$max_expLast10, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))

avg_maxdata = rbind(cbind(max_a, phase=rep("untimed practice", nrow(max_a))), 
                    cbind(max_b, phase=rep("deadline early", nrow(max_b))), 
                    cbind(max_c, phase=rep("deadline late", nrow(max_c))))
avg_maxdata$phase = as.factor(avg_maxdata$phase)         # Convert phase to factor
levels(avg_maxdata$condition) = c("fixed", "random") # Replace condition names

# Set up summary data dataframe: minimum partial completion efficiency
min_a = setNames(aggregate(expdata$min_practice, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))
min_b = setNames(aggregate(expdata$min_expFirst10, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))
min_c = setNames(aggregate(expdata$min_expLast10, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))

avg_mindata = rbind(cbind(min_a, phase=rep("untimed practice", nrow(min_a))), 
                    cbind(min_b, phase=rep("deadline early", nrow(min_b))), 
                    cbind(min_c, phase=rep("deadline late", nrow(min_c))))
avg_mindata$phase = as.factor(avg_mindata$phase)         # Convert phase to factor
levels(avg_mindata$condition) = c("fixed", "random") # Replace condition names

# Set up summary data dataframe: avg partial completion efficiency
avg_a = setNames(aggregate(expdata$avg_practice, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))
avg_b = setNames(aggregate(expdata$avg_expFirst10, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))
avg_c = setNames(aggregate(expdata$avg_expLast10, by=list(expdata$condition, expdata$subject), mean), c("condition", "subject", "avg"))

avg_avgdata = rbind(cbind(avg_a, phase=rep("untimed practice", nrow(avg_a))), 
                    cbind(avg_b, phase=rep("deadline early", nrow(avg_b))), 
                    cbind(avg_c, phase=rep("deadline late", nrow(avg_c))))
avg_avgdata$phase = as.factor(avg_avgdata$phase)         # Convert phase to factor
levels(avg_avgdata$condition) = c("fixed", "random") # Replace condition names


# Set up summary data for matches
set1 = cbind(rep("fixed",fd$nSubjects), rep("untimed" ,fd$nSubjects), scores$fixed$practice$matches)
names(set1) = c("condition", "phase", "subjects", "match1", "match2", "match3")
set2 = cbind(rep("fixed",fd$nSubjects), rep("deadline" ,fd$nSubjects), scores$fixed$experiment$matches)
names(set2) = c("condition", "phase", "subjects", "match1", "match2", "match3")
set3 = cbind(rep("random",rd$nSubjects), rep("untimed" ,rd$nSubjects), scores$random$practice$matches)
names(set3) = c("condition", "phase", "subjects", "match1", "match2", "match3")
set4 = cbind(rep("random",rd$nSubjects), rep("deadline" ,rd$nSubjects), scores$random$experiment$matches)
names(set4) = c("condition", "phase", "subjects", "match1", "match2", "match3")

match_mat = rbind(set1, set2, set3, set4)

```

As in Experiment 1, we have established that the RDK's are ordered in accuracy, difficulty, and reward rate. The analysis of optimality also replicated the results for Experiment 1.

* What is the proportion of easy, medium, hard, and very hard patches selected first, second, third or fourth?

The ordering of choices is more optimal when the locations are fixed and subtask order becomes more optimal under a deadline. By contrast, when locations are random, responding becomes _less_ optimal under a deadline. Again, this likely reflects the additional costs of having to search for the appropriate task to complete. 

```{r selectionOrderAnalysis, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}

# selection_counts [rows are choice order (1,2,3,4), columns are diffculty (easy,med, hard,vhard)]

# Convert to proportions
fpmat = t(apply(scores$fixed$practice$selection_counts, 1, function(x) x/sum(x)))
femat = t(apply(scores$fixed$experiment$selection_counts, 1, function(x) x/sum(x)))
rpmat = t(apply(scores$random$practice$selection_counts, 1, function(x) x/sum(x)))
remat = t(apply(scores$random$experiment$selection_counts, 1, function(x) x/sum(x)))

fpmelt = melt(fpmat)
femelt = melt(femat)
rpmelt = melt(rpmat)
remelt = melt(remat)
names(fpmelt) = c("Difficulty", "Order", "value")
names(femelt) = c("Difficulty", "Order", "value")
names(rpmelt) = c("Difficulty", "Order", "value")
names(remelt) = c("Difficulty", "Order", "value")

hm = rbind(cbind("condition" = rep("Fixed No Deadline", nrow(fpmelt)), fpmelt), 
           cbind("condition" = rep("Fixed Deadline", nrow(fpmelt)), femelt),
           cbind("condition" = rep("Random No Deadline", nrow(fpmelt)), rpmelt),
           cbind("condition" = rep("Random Deadline", nrow(fpmelt)), remelt))

hmplot = ggplot(hm, aes(x=Difficulty, y=Order)) +
          geom_tile(aes(fill=value)) +
          scale_fill_gradientn(colours=c("blue","pink", "red")) +
          geom_text(aes(label=round(value, 2))) + 
          scale_y_reverse() +
          facet_wrap(~condition) + 
          labs(y="Choice", x = "Difficulty")
print(hmplot)

```

* What is the proportion of easy-task-first choices in each condition? Of easy-then-medium? Of easy-medium-then-hard? This provides an indication of how the order of responding deviates from optimal in each condition. The table presents the proportion of subjects responding with each order; the figure presents the frequency with which subjects respond with the easiest first RDK, easiest then medium, and so on.

```{r analyseMatches, fig.height = 10, fig.width = 9, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
avgMatch = aggregate(list("easy first"=match_mat$match1, "easy-med"=match_mat$match2, "easy-med-hard"=match_mat$match3), by = list("phase"=match_mat$phase, "condition"=match_mat$condition), FUN = function(x)mean(x,na.rm=TRUE))

avgMatch$easy.first = round(avgMatch$easy.first,2)
avgMatch$easy.med = round(avgMatch$easy.med,2)
avgMatch$easy.med.hard = round(avgMatch$easy.med.hard,2)

# Create the table
kable(avgMatch, caption="Average optimal choices")

long_match = melt(match_mat, id.var = c("condition", "phase"), measure.var = c("match1", "match2", "match3"), variable.name = "match")
levels(long_match$match) = c("Order = Easy", "Order = Easy, Medium", "Order = Easy, Medium, Hard")

match_plot <- long_match %>% ggplot(aes(x=value, fill=match)) + geom_histogram(color="white", alpha=0.6, bins = 10, position="identity") + facet_wrap(~condition+phase+match, nrow=4, ncol = 3) + labs(y="Participant Frequency", x = "Proportion of First Choices")

print(match_plot + ggtitle("Optimally Ordered Responses")) 

```

* How optimal were responses? 

The following figures compare max_distance, min_distance, and avg_distance between the fixed difficulty and random difficulty conditions as a function of deadline condition and phase. For each of these measures, lower values reflect respones which are closer to optimal.

```{r plotData, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
max_plot <- avg_maxdata %>% ggplot(aes(x=avg, fill=phase)) + geom_histogram(color="white", alpha=0.6, bins = 10, position="identity") + facet_wrap(~condition+phase) + labs(y="Frequency", x = "Max Distance")

min_plot <- avg_mindata %>% ggplot(aes(x=avg, fill=phase)) + geom_histogram(color="white", alpha=0.6, bins = 10, position="identity") + facet_wrap(~condition+phase) + labs(y="Frequency", x = "Min Distance")

avg_plot <- avg_avgdata %>% ggplot(aes(x=avg, fill=phase)) + geom_histogram(color="white", alpha=0.6, bins = 10, position="identity") + facet_wrap(~condition+phase) + labs(y="Frequency", x = "Avg Distance")

print(max_plot + ggtitle("Max Distance"))
print(min_plot + ggtitle("Min Distance"))
print(avg_plot + ggtitle("Avg Distance"))

```

## Sampling distribution anlaysis

In order to characterise performance, we again computed the ks-test statistic between the data (the average partial distance data) and the random order distribution and the first-two optimal distribution. Recall that values less than one indicate that the data are more consistent with random than optimal responding. Values greater than one indicate that the data are more consistent with optimal rather than random responding. 

```{r sampling_dist, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}

opt_order_dist = function(trial_optimal_order, nperms=nperms, allperms=allperms){
  pdist <- rep(NA, nperms)
  for (i in 1:nperms){
    distObj = ConDisPairs(table(allperms[i, ], trial_optimal_order))
    pdist[i] = distObj$D  
  }
  return(pdist)
}

opt_order = c(1,2,3,4)
opt_dist_list = opt_order_dist(opt_order, nperms, allperms)

nsamples = 1000

# sample a bunch of orders, and compute the distances
allrand = as.data.frame(list("s" = sample(opt_dist_list, nsamples, replace = TRUE)))
onefix = as.data.frame(list("s" = sample(opt_dist_list[allperms[,1]==1], nsamples, replace = TRUE)))
twofix = as.data.frame(list("s" = sample(opt_dist_list[allperms[,1]==1 & allperms[,2]==2], nsamples, replace = TRUE)))
distance_samples = as.data.frame(rbind(cbind("cond" = rep(1, nsamples), "s" = allrand$s), cbind("cond" = rep(2, nsamples), "s" = onefix$s), cbind("cond" = rep(3, nsamples), "s" = twofix$s)))


# plot the distribution of distances
samp_plot <- distance_samples %>% ggplot(aes(s)) + 
  geom_histogram(color="white", alpha =0.8, bins=7, position="identity") + 
  labs(y = "Frequency of Sample", x = "Distance From Optimal") + 
  facet_wrap(~cond)
print(samp_plot)

# Statistical comparison
#ks.test(avg_avgdata$avg[avg_avgdata$condition == "fixed" & avg_avgdata$phase == "deadline early"], avg_avgdata$avg[avg_avgdata$condition == "fixed" & avg_avgdata$phase == "deadline late"])

# Lower values of the ks test indicate higher similarity between the distributions, so compare the ratio of optimal vs random distances at each time point
# Note: you don't have to sample for the kstest, you can just use the actual values, but sampling is fine
# > 1 indicates more optimal than random, < 1 indicates more random than optimal

ks.fixed.phase1 = ks.test(allrand$s, avg_avgdata$avg[avg_avgdata$condition == "fixed" & avg_avgdata$phase == "untimed practice"])$statistic/ks.test(twofix$s, avg_avgdata$avg[avg_avgdata$condition == "fixed" & avg_avgdata$phase == "untimed practice"])$statistic

ks.fixed.phase2 = ks.test(allrand$s, avg_avgdata$avg[avg_avgdata$condition == "fixed" & avg_avgdata$phase == "deadline early"])$statistic/ks.test(twofix$s, avg_avgdata$avg[avg_avgdata$condition == "fixed" & avg_avgdata$phase == "deadline early"])$statistic

ks.fixed.phase3 = ks.test(allrand$s, avg_avgdata$avg[avg_avgdata$condition == "fixed" & avg_avgdata$phase == "deadline late"])$statistic/ks.test(twofix$s, avg_avgdata$avg[avg_avgdata$condition == "fixed" & avg_avgdata$phase == "deadline late"])$statistic

ks.random.phase1 = ks.test(allrand$s, avg_avgdata$avg[avg_avgdata$condition == "random" & avg_avgdata$phase == "untimed practice"])$statistic/ks.test(twofix$s, avg_avgdata$avg[avg_avgdata$condition == "random" & avg_avgdata$phase == "untimed practice"])$statistic

ks.random.phase2 = ks.test(allrand$s, avg_avgdata$avg[avg_avgdata$condition == "random" & avg_avgdata$phase == "deadline early"])$statistic/ks.test(twofix$s, avg_avgdata$avg[avg_avgdata$condition == "random" & avg_avgdata$phase == "deadline early"])$statistic

ks.random.phase3 = ks.test(allrand$s, avg_avgdata$avg[avg_avgdata$condition == "random" & avg_avgdata$phase == "deadline late"])$statistic/ks.test(twofix$s, avg_avgdata$avg[avg_avgdata$condition == "random" & avg_avgdata$phase == "deadline late"])$statistic

# Build data for plotting
randomness = as.data.frame(list("condition" = factor(c("fixed", "fixed", "fixed", "random", "random", "random"), levels =c("fixed", "random")), "phase" = factor(c("untimed", "deadline early", "deadline late", "untimed", "deadline early", "deadline late"), levels = c("untimed", "deadline early", "deadline late")), "ratio" = c(ks.fixed.phase1, ks.fixed.phase2, ks.fixed.phase3, ks.random.phase1, ks.random.phase2, ks.random.phase3)))
levels(randomness$phase) = c("untimed", "deadline early", "deadline late")

# Plot
random_eval_plot <- randomness %>% ggplot(aes(x=phase, y=ratio, group=condition)) + 
                     geom_line(aes(linetype=condition), size=1) +
                     geom_point(size=4) + 
                     labs(y="Ratio (Random Distance/Optimal Distance)", x = "Phase") + 
                     ggtitle("Comparison to random and optimal sampling distributions") + 
                     geom_hline(yintercept =1, linetype="dotted", color="black", size=.5)
print(random_eval_plot)

```

As in Experiment 1, responding is more optimal in the fixed deadline condition particularly during the last ten trials; in the random deadline conditions, responding was closer to a random sampling distribution than to an optimal sampling distribution. 

## Alternative response strategies

Also as like Experiment 1, there was little evidence of a spatial response strategy. 

```{r spatial_analysis, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}

clockwise = rbind(c(0, 1, 2, 3), c(1, 2, 3, 0), c(2, 3, 0, 1), c(3, 0, 1, 2))
anticlockwise = rbind(c(0, 3, 2, 1), c(1, 0, 3, 2), c(2, 1, 0, 3), c(3, 2, 1, 0))
spatial_orders = rbind(clockwise, anticlockwise)

# Code whether each selection is consistent or inconsistent with a circular strategy
get_spatial_consistency = function(sdata, spatial_orders, ntrials, n, nSubjects, subjects){
  
  # preallocate variables for output
  spatial_choice_scores <- matrix(data=NA, nrow=nSubjects, ncol=ntrials)
  spatial_display_scores <- matrix(data=NA, nrow=nSubjects, ncol=ntrials)
  for (j in 1:nSubjects){
    # select out data for subject j
    tdata = sdata[sdata$uniqueid == subjects[j], ]
    
    # preallocated subject specific task selection matrix
    #selmat <- matrix(data=NA, nrow=ntrials, ncol=n)
    for (i in 1:ntrials){

        # Get the task selection order for the current trial (may be incomplete if timed out)
        csel = tdata[tdata$trial_number == i-1, ]$button_pressed+1
        #csel[csel==5] = NA # NULL is coded as option 5, Replace NULL with NA
        #csel = as.numeric(as.character(as.matrix(csel)))
        
        #selmat[i, 1:length(csel)] = csel # NULL is coded as option 5
        #selmat[i, selmat[i,] == 5] = NA  # Replace NULL with NA
        
        # Get coherence order for the current trial
        coh = c(tdata[tdata$trial_number == i-1, ]$patch_0[1], tdata[tdata$trial_number == i-1, ]$patch_1[1], tdata[tdata$trial_number == i-1, ]$patch_2[1], tdata[tdata$trial_number == i-1, ]$patch_3[1])
        
        cohOrder = order(coh) # Locations of each difficulty (very hard, hard, med, easy)
        
        # Code trial and coherence as spatially consistent or not
        spatial_choice_scores[j,i] = as.numeric(any(apply(spatial_orders[ , 1:3], 1, function(x) identical(x, csel[1:3]))))
        spatial_display_scores[j,i] = as.numeric(any(apply(spatial_orders[ , 1:3], 1, function(x) identical(x, cohOrder[1:3]-1))))
    }
  }
  return(list("choice" = spatial_choice_scores, "display" = spatial_display_scores))
}


# Compute responses consistent with a spatial strategy
# sdata, spatial_orders, ntrials, n, nSubjects, subjects
spatial_scores = list("fixed" = list("practice" = get_spatial_consistency(splitData(fd$data)$practice, spatial_orders, 10, 
                                                         n, fd$nSubjects, fd$subjects), 
                            "experiment" = get_spatial_consistency(splitData(fd$data)$experiment, spatial_orders, 30,
                                                         n, fd$nSubjects, fd$subjects)), 
             "random" = list("practice" = get_spatial_consistency(splitData(rd$data)$practice, spatial_orders, 10, 
                                                         n, rd$nSubjects, rd$subjects), 
                            "experiment" = get_spatial_consistency(splitData(rd$data)$experiment, spatial_orders, 30,
                                                         n, rd$nSubjects, rd$subjects)))

```


```{r buildSpatialComparison, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
fscon = data.frame(condition = as.factor(rep(1, fd$nSubjects*10)), 
                  subjects = rep(1:fd$nSubjects + 100, each=10), 
                  trials = rep(1:10, fd$nSubjects), 
                  sc_practice = matrix(t(spatial_scores$fixed$practice$choice), 10*nrow(spatial_scores$fixed$practice$choice), byrow= FALSE), 
                  sc_expFirst10 = matrix(t(spatial_scores$fixed$experiment$choice[, 1:10]), 10*nrow(spatial_scores$fixed$experiment$choice), byrow= FALSE), 
                  sc_expLast10 = matrix(t(spatial_scores$fixed$experiment$choice[, 21:30]), 10*nrow(spatial_scores$fixed$experiment$choice), byrow= FALSE), 
                  sd_practice = matrix(t(spatial_scores$fixed$practice$display), 10*nrow(spatial_scores$fixed$practice$display), byrow= FALSE), 
                  sd_expFirst10 = matrix(t(spatial_scores$fixed$experiment$display[, 1:10]), 10*nrow(spatial_scores$fixed$experiment$display), byrow= FALSE), 
                  sd_expLast10  = matrix(t(spatial_scores$fixed$experiment$display[, 21:30]), 10*nrow(spatial_scores$fixed$experiment$display), byrow= FALSE))

rscon = data.frame(condition = as.factor(rep(2, rd$nSubjects*10)), 
                  subjects = rep(1:rd$nSubjects + 200, each=10), 
                  trials = rep(1:10, rd$nSubjects), 
                  sc_practice = matrix(t(spatial_scores$random$practice$choice), 10*nrow(spatial_scores$random$practice$choice), byrow= FALSE), 
                  sc_expFirst10 = matrix(t(spatial_scores$random$experiment$choice[, 1:10]), 10*nrow(spatial_scores$random$experiment$choice), byrow= FALSE), 
                  sc_expLast10 = matrix(t(spatial_scores$random$experiment$choice[, 21:30]), 10*nrow(spatial_scores$random$experiment$choice), byrow= FALSE), 
                  sd_practice = matrix(t(spatial_scores$random$practice$display), 10*nrow(spatial_scores$random$practice$display), byrow= FALSE), 
                  sd_expFirst10 = matrix(t(spatial_scores$random$experiment$display[, 1:10]), 10*nrow(spatial_scores$random$experiment$display), byrow= FALSE), 
                  sd_expLast10  = matrix(t(spatial_scores$random$experiment$display[, 21:30]), 10*nrow(spatial_scores$random$experiment$display), byrow= FALSE))

spatialdata = rbind(fscon, rscon)

# Set up summary data dataframe: spatial choice consistency
sc_a = setNames(aggregate(spatialdata$sc_practice, by=list(spatialdata$condition, spatialdata$subject), mean), c("condition", "subject", "avg"))
sc_b = setNames(aggregate(spatialdata$sc_expFirst10, by=list(spatialdata$condition, spatialdata$subject), mean), c("condition", "subject", "avg"))
sc_c = setNames(aggregate(spatialdata$sc_expLast10, by=list(spatialdata$condition, spatialdata$subject), mean), c("condition", "subject", "avg"))

avg_scdata = rbind(cbind(sc_a, phase=rep("untimed practice", nrow(sc_a))), 
                    cbind(sc_b, phase=rep("deadline early", nrow(sc_b))), 
                    cbind(sc_c, phase=rep("deadline late", nrow(sc_c))))
avg_scdata$phase = as.factor(avg_scdata$phase)         # Convert phase to factor
levels(avg_scdata$condition) = c("fixed", "random") # Replace condition names

# Set up summary data dataframe: spatial display consistency
sd_a = setNames(aggregate(spatialdata$sd_practice, by=list(spatialdata$condition, spatialdata$subject), mean), c("condition", "subject", "avg"))
sd_b = setNames(aggregate(spatialdata$sd_expFirst10, by=list(spatialdata$condition, spatialdata$subject), mean), c("condition", "subject", "avg"))
sd_c = setNames(aggregate(spatialdata$sd_expLast10, by=list(spatialdata$condition, spatialdata$subject), mean), c("condition", "subject", "avg"))

avg_sddata = rbind(cbind(sd_a, phase=rep("untimed practice", nrow(sd_a))), 
                    cbind(sd_b, phase=rep("deadline early", nrow(sd_b))), 
                    cbind(sd_c, phase=rep("deadline late", nrow(sd_c))))
avg_sddata$phase = as.factor(avg_sddata$phase)         # Convert phase to factor
levels(avg_sddata$condition) = c("fixed", "random") # Replace condition names

```
```{r plotSpatialData, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
spatial_choice_plot <- avg_scdata %>% ggplot(aes(x=avg, fill=phase)) + geom_histogram(color="white", alpha=0.6, bins = 10, position="identity") + facet_wrap(~condition+phase) + labs(y="Frequency", x = "Proportion of Spatially Consistent Responses") + ggtitle("Spatial Strategy Analysis")

#avg_plot <- avg_avgdata %>% ggplot(aes(x=avg, fill=phase+phase)) + geom_histogram(color="white", alpha=1, bins = 10) + facet_wrap(~condition+phase)

print(spatial_choice_plot)

```
